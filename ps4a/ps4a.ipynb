{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ps4a\n",
    "Ej Zhou (yz2876) and Jiawei Sun (js2869) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import grammar, parse\n",
    "from nltk.parse.generate import generate\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable, List, Set\n",
    "\n",
    "def to_model_str(word: str, special_rels: List[Callable[[str], str]]=[]) -> str:\n",
    "    \"\"\"\n",
    "    Creates the string form of the model for the input word. This string is meant to be passed to `nltk.Valuation.fromstring`.\n",
    "    By default, the function will only add the relations mapping i => i for i from 1 to the length of `word` and a relation \n",
    "    mapping char => the set of tuples (i, word[i]). The `special_rels` function allows you to specify additional relations to \n",
    "    be added to the valuation string.\n",
    "    \n",
    "    :param word: The word to create a model string for.\n",
    "    :param special_rels: A list of functions that when called return a string of the form {relation_name} => {relation_contents}. Defaults to the empty list.\n",
    "    :returns: a string representing the model for word\n",
    "    \"\"\"\n",
    "    n = len(word)\n",
    "    model_str = []\n",
    "    char = []\n",
    "    for i in range(1, n+1):\n",
    "        model_str.append(f'{i} => {i}')\n",
    "        char.append((i, word[i-1]))\n",
    "    model_str.append(f'char => {set(char)}'.lower())\n",
    "    return '\\n'.join(model_str + [rel(word) for rel in special_rels]).replace(\"'\", \"\")\n",
    "# Angela Liu\n",
    "\n",
    "import re\n",
    "get_vowel = lambda w: f'vowel => {set(re.findall(r\"[AEIOUaeiou]\", w))}'.lower()\n",
    "get_cons = lambda w: 'cons => {}'.format(set(re.findall(r\"[^AEIOUaeiou\\W0-9]\", w))).lower()\n",
    "follows = lambda w: f'le => {set([(i+1,j+1) for i in range(len(w)) for j in range(i, len(w)) if i != j])}'\n",
    "get_capital = lambda w: f'capital => {set([m.span()[0] + 1 for m in re.finditer(r\"[A-Z]\", w)])}'\n",
    "# Angela Liu\n",
    "\n",
    "def emptysets(val:nltk.sem.evaluate.Valuation):\n",
    "  val.update([(k,set()) for (k,v) in val.items() if v == 'set()'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#for w, m in zip(words, models):\n",
    "    #print(f'{w}\\n----------------\\n{m}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Number feature. The following sentences illustrate number agreement\n",
    "between subjects, verb phrases, and within DPs.\n",
    "\n",
    "No vowels are capitalized.\n",
    "* No vowels is capitalized.\n",
    "\n",
    "No vowel is capitalized.\n",
    "* No vowel are capitalized.\n",
    "\n",
    "Exactly two vowels are capitalized.\n",
    "*Exactly two vowels is capitalized.\n",
    "\n",
    "*Exactly two vowel\n",
    "Exactly two vowels\n",
    "\n",
    "Exactly one vowel\n",
    "*Exactly one vowels\n",
    "\n",
    "Create a feature grammar including semantics that has singular and plural\n",
    "determiners, singular and plural DPs, and singular and plural VPs, and\n",
    "enforces agreement correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "parser_str = '''\n",
    "% start S\n",
    "#Grammar Rules\n",
    "S[NUM='sg',SEM=<?X(?P)>] -> DP[NUM='sg', SEM=?X] VP[NUM='sg', SEM=?P]\n",
    "S[NUM='pl',SEM=<?X(?P)>] -> DP[NUM='pl', SEM=?X] VP[NUM='pl', SEM=?P] \n",
    "\n",
    "DP[NUM='sg',SEM=<?X(?P)>] -> Det[NUM='sg',SEM=?X] N[NUM='sg', SEM=?P] \n",
    "DP[NUM='pl',SEM=<?X(?P)>] -> Det[NUM='pl',SEM=?X] N[NUM='pl', SEM=?P] \n",
    "\n",
    "VP[NUM='sg',SEM=?Q] -> 'is' JJ[SEM=?Q]\n",
    "VP[NUM='pl',SEM=?Q] -> 'are' JJ[SEM=?Q]\n",
    "Det[SEM=<?X(?P)>] -> Det[SEM=?X] Det[SEM=?P]\n",
    "#Lexical Rules\n",
    "Det[SEM=<\\P Q.all n.-(P(n) & Q(n))>] -> 'no'\n",
    "\n",
    "Det[NUM='sg', SEM=<\\P Q.exists n.((P(n) & Q(n)) & all m.((n != m) -> -(P(m)&Q(m))))>] -> 'exactly' 'one'\n",
    "\n",
    "Det[NUM='pl',SEM=<\\P Q.exists n.(((P(n)&Q(n))& exists m.((n!=m)&P(m)&Q(m)& all p.(((n!=p)&(m!=p))-> -(P(p)&Q(p))))))>] -> 'exactly' 'two'\n",
    "\n",
    "JJ[SEM=<\\c.(capital(c))>] -> 'capitalized'\n",
    "N[NUM='sg',SEM=<\\m.exists c.(vowel(c) & char(m,c))>] -> 'vowel'\n",
    "N[NUM='pl',SEM=<\\m.exists c.(vowel(c) & char(m,c))>] -> 'vowels'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "grammar = nltk.grammar.FeatureGrammar.fromstring(parser_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "p = nltk.parse.FeatureChartParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sens2 = []\n",
    "sens2.append('no vowels is capitalized'.split())\n",
    "sens2.append('no vowel are capitalized'.split())\n",
    "sens2.append('exactly two vowel are capitalized'.split())\n",
    "sens2.append('exactly one vowels are capitalized'.split())\n",
    "sens2.append('exactly two vowels is capitalized'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" no vowels is capitalized \"  is not a valid sentence\n",
      "\" no vowel are capitalized \"  is not a valid sentence\n",
      "\" exactly two vowel are capitalized \"  is not a valid sentence\n",
      "\" exactly one vowels are capitalized \"  is not a valid sentence\n",
      "\" exactly two vowels is capitalized \"  is not a valid sentence\n"
     ]
    }
   ],
   "source": [
    "for sen in sens2:\n",
    "    try:\n",
    "        t = next(p.parse(sen))\n",
    "    except:\n",
    "        print('\"',' '.join(sen),'\"', ' is not a valid sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "wordslist2 = [(\"jack\",True), # no vowel capitalized \n",
    "          (\"klAus\",False), # one vowel capitalized\n",
    "          (\"cOAmp\",False), # two vowel capitalized\n",
    "          (\"cOAEmp\",False)] # three vowel capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sens3 = []\n",
    "sens3.append('no vowel is capitalized'.split())\n",
    "sens3.append('exactly one vowel is capitalized'.split())\n",
    "sens3.append('exactly two vowels are capitalized'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'vowel', 'is', 'capitalized']\n",
      "---------------\n",
      "jack\n",
      "True\n",
      "----------------\n",
      "klAus\n",
      "False\n",
      "----------------\n",
      "cOAmp\n",
      "False\n",
      "----------------\n",
      "cOAEmp\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n",
      "['exactly', 'one', 'vowel', 'is', 'capitalized']\n",
      "---------------\n",
      "jack\n",
      "False\n",
      "----------------\n",
      "klAus\n",
      "True\n",
      "----------------\n",
      "cOAmp\n",
      "False\n",
      "----------------\n",
      "cOAEmp\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n",
      "['exactly', 'two', 'vowels', 'are', 'capitalized']\n",
      "---------------\n",
      "jack\n",
      "False\n",
      "----------------\n",
      "klAus\n",
      "False\n",
      "----------------\n",
      "cOAmp\n",
      "True\n",
      "----------------\n",
      "cOAEmp\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sen in sens3:\n",
    "    #Setting up Sentence Semantics\n",
    "    t = next(p.parse(sen))\n",
    "    fn = t.label()['SEM']\n",
    "\n",
    "    #Setting up Truth Values\n",
    "    words = [e[0] for e in wordslist2]\n",
    "    truths = [e[1] for e in wordslist2]\n",
    "    vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_capital])) for w in words]\n",
    "    assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "    for val in vals: emptysets(val)\n",
    "    models = [nltk.Model(val.domain, val) for val in vals]\n",
    "    \n",
    "    #Print Results\n",
    "    print(f'{sen}\\n---------------')\n",
    "    for w, a, m in zip(words, assignments, models):\n",
    "        print(f'{w}\\n{m.evaluate(str(fn),a)}\\n----------------')\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. There insertion\n",
    "\n",
    "There are at least two vowels.\n",
    "There are exactly two vowels.\n",
    "There are no vowels vowels.\n",
    "There are some vowels vowels.\n",
    "\n",
    "* There is every vowel.\n",
    "* There are most vowels.\n",
    "\n",
    "There is exactly one consonant.\n",
    "There is no consonant.\n",
    "\n",
    "Notice these points.\n",
    "\n",
    "(i) The set of determiners that can occur in there-insertion is\n",
    "restricted.  These are called weak determiners. Use a feature\n",
    "to distinguish weak determ2iners from strong ones.\n",
    "\n",
    "(ii) The verb is/are agrees in number with the phrase that follows.\n",
    "\n",
    "Write a grammar (based on the one from Problem 1) that enforces the\n",
    "restrictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ps2 = '''\n",
    "% start S\n",
    "#Grammar Rules\n",
    "S[NUM='sg',STR='weak',SEM=<?X>] -> PP[NUM='sg',STR='weak'] DP[NUM='sg',STR='weak', SEM=?X]\n",
    "S[NUM='pl',STR='weak',SEM=<?X>] -> PP[NUM='pl',STR='weak'] DP[NUM='pl',STR='weak', SEM=?X]\n",
    "\n",
    "DP[NUM='sg',STR='weak',SEM=<?X(?P)>] -> Det[NUM='sg',STR='weak',SEM=?X] N[NUM='sg', SEM=?P] \n",
    "DP[NUM='pl',STR='weak',SEM=<?X(?P)>] -> Det[NUM='pl',STR='weak',SEM=?X] N[NUM='pl', SEM=?P] \n",
    "\n",
    "DP[NUM='sg',STR='strong',SEM=<?X(?P)>] -> Det[NUM='sg', STR='strong',SEM=?X] N[NUM='sg', SEM=?P] \n",
    "DP[NUM='pl',STR='strong',SEM=<?X(?P)>] -> Det[NUM='pl', STR='strong',SEM=?X] N[NUM='pl', SEM=?P] \n",
    "\n",
    "Det[SEM=<?X(?P)>] -> Det[SEM=?X] Det[SEM=?P]\n",
    "\n",
    "PP[NUM='sg', STR='weak'] -> P[STR='weak'] 'is'\n",
    "PP[NUM='pl', STR='weak'] -> P[STR='weak'] 'are'\n",
    "\n",
    "#Lexical Rules\n",
    "Det[STR='weak', SEM=<\\P.all n.-(P(n))>] -> 'no'\n",
    "\n",
    "Det[NUM='sg', STR='strong', SEM=<\\P.all n.(P(n))>] -> 'every'\n",
    "\n",
    "Det[NUM='pl', STR='weak', SEM=<\\P.exists n.(P(n))>] -> 'some'\n",
    "Det[NUM='pl', STR='strong', SEM=<\\P.exists n.(P(n))>] -> 'most'\n",
    "\n",
    "\n",
    "Det[NUM='sg', STR='weak', SEM=<\\P.exists n.((P(n)) & all m.((n != m) -> -(P(m))))>] -> 'exactly' 'one'\n",
    "\n",
    "Det[NUM='pl',STR='weak',SEM=<\\P.exists n.((P(n)& exists m.((n!=m)&P(m)& all p.(((n!=p)&(m!=p))-> -(P(p))))))>] -> 'exactly' 'two'\n",
    "\n",
    "Det[NUM='pl',STR='weak',SEM=<\\P.exists n.(P(n)& exists m.((n!=m)&P(m)))>] -> 'at' 'least' 'two'\n",
    "\n",
    "P[STR='weak'] -> 'there'\n",
    "\n",
    "N[NUM='sg',SEM=<\\m.exists c.(vowel(c) & char(m,c))>] -> 'vowel'\n",
    "N[NUM='pl',SEM=<\\m.exists c.(vowel(c) & char(m,c))>] -> 'vowels'\n",
    "\n",
    "N[NUM='sg',SEM=<\\m.exists c.(cons(c) & char(m,c))>] -> 'consonant'\n",
    "N[NUM='pl',SEM=<\\m.exists c.(cons(c) & char(m,c))>] -> 'consonants'\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "g2 = nltk.grammar.FeatureGrammar.fromstring(ps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "p2 = nltk.parse.FeatureChartParser(g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sens2 = []\n",
    "sens2.append('there is every vowel'.split())\n",
    "sens2.append('there are most vowels'.split())\n",
    "sens2.append('there is no vowels'.split())\n",
    "sens2.append('there is at least two vowels'.split())\n",
    "sens2.append('there are exactly one consonant'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" there is every vowel \"  is not a valid sentence\n",
      "\" there are most vowels \"  is not a valid sentence\n",
      "\" there is no vowels \"  is not a valid sentence\n",
      "\" there is at least two vowels \"  is not a valid sentence\n",
      "\" there are exactly one consonant \"  is not a valid sentence\n"
     ]
    }
   ],
   "source": [
    "for sen in sens2:\n",
    "    try:\n",
    "        t = next(p2.parse(sen))\n",
    "    except:\n",
    "        print('\"',' '.join(sen),'\"', ' is not a valid sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "wordslist = [(\"jck\",True), # no vowel, three consonants\n",
    "          (\"jac\",False), # one vowel, two consonants\n",
    "          (\"cOA\",False), # two vowel, one consonant\n",
    "          (\"OAE\",False)] # three vowels, no consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sens = []\n",
    "sens.append('there are at least two vowels'.split())\n",
    "sens.append('there are exactly two vowels'.split())\n",
    "sens.append('there are no vowels'.split())\n",
    "sens.append('there are some vowels'.split())\n",
    "sens.append('there are at least two consonants'.split())\n",
    "sens.append('there is exactly one consonant'.split())\n",
    "sens.append('there is no consonant'.split())\n",
    "sens.append('there are some consonants'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['there', 'are', 'at', 'least', 'two', 'vowels']\n",
      "---------------\n",
      "jck\n",
      "False\n",
      "----------------\n",
      "jac\n",
      "False\n",
      "----------------\n",
      "cOA\n",
      "True\n",
      "----------------\n",
      "OAE\n",
      "True\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'are', 'exactly', 'two', 'vowels']\n",
      "---------------\n",
      "jck\n",
      "False\n",
      "----------------\n",
      "jac\n",
      "False\n",
      "----------------\n",
      "cOA\n",
      "True\n",
      "----------------\n",
      "OAE\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'are', 'no', 'vowels']\n",
      "---------------\n",
      "jck\n",
      "True\n",
      "----------------\n",
      "jac\n",
      "False\n",
      "----------------\n",
      "cOA\n",
      "False\n",
      "----------------\n",
      "OAE\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'are', 'some', 'vowels']\n",
      "---------------\n",
      "jck\n",
      "False\n",
      "----------------\n",
      "jac\n",
      "True\n",
      "----------------\n",
      "cOA\n",
      "True\n",
      "----------------\n",
      "OAE\n",
      "True\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'are', 'at', 'least', 'two', 'consonants']\n",
      "---------------\n",
      "jck\n",
      "True\n",
      "----------------\n",
      "jac\n",
      "True\n",
      "----------------\n",
      "cOA\n",
      "False\n",
      "----------------\n",
      "OAE\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'is', 'exactly', 'one', 'consonant']\n",
      "---------------\n",
      "jck\n",
      "False\n",
      "----------------\n",
      "jac\n",
      "False\n",
      "----------------\n",
      "cOA\n",
      "True\n",
      "----------------\n",
      "OAE\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'is', 'no', 'consonant']\n",
      "---------------\n",
      "jck\n",
      "False\n",
      "----------------\n",
      "jac\n",
      "False\n",
      "----------------\n",
      "cOA\n",
      "False\n",
      "----------------\n",
      "OAE\n",
      "True\n",
      "----------------\n",
      "\n",
      "\n",
      "['there', 'are', 'some', 'consonants']\n",
      "---------------\n",
      "jck\n",
      "True\n",
      "----------------\n",
      "jac\n",
      "True\n",
      "----------------\n",
      "cOA\n",
      "True\n",
      "----------------\n",
      "OAE\n",
      "False\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sen in sens:\n",
    "    #Setting up Sentence Semantics\n",
    "    t = next(p2.parse(sen))\n",
    "    fn = t.label()['SEM']\n",
    "    \n",
    "    #Setting up Truth Values\n",
    "    words = [e[0] for e in wordslist]\n",
    "    truths = [e[1] for e in wordslist]\n",
    "    vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_cons])) for w in words]\n",
    "    assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "    for val in vals: emptysets(val)\n",
    "    models = [nltk.Model(val.domain, val) for val in vals]\n",
    "    \n",
    "    #Print Results\n",
    "    print(f'{sen}\\n---------------')\n",
    "    for w, a, m in zip(words, assignments, models):\n",
    "        print(f'{w}\\n{m.evaluate(str(fn),a)}\\n----------------')\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Make a selection of ten sentences about strings. One method is to modify\n",
    "sentences from challenge problems for ps2.\n",
    "\n",
    "Pick a nickname for yourself, say 'ayako'.  Record the sentences as wav files\n",
    "ayako-a-1.wav ... ayako-a-10.wav.   \n",
    "\n",
    "Check on the forum for specifications regarding sample rate and the like.\n",
    "Install the sentences on kuno in a location that will be specied on\n",
    "the forum.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scp.png](sftp.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![wav](wav.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sftp> put *.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Kaldi setup\n",
    "Set up jupyter and bash kernel on kuno. In a jupyter bash notebook, do\n",
    "these things.\n",
    "\n",
    "a. Run the demo run.sh in egs/yesno in the notebook, using your own\n",
    "copy of egs/yesno.\n",
    "\n",
    "b. Using kaldi tools, print a matrix with the first ten rows and first five columns of\n",
    "one of the utterances.  Methodology will be covered in class.\n",
    "The relevant programs are in featbin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cp](CP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd /projects/speech/ASR/kaldi/egs/yesno\n",
    "cp -R s5-clean s5-yz2876\n",
    "cd s5-yz2876/\n",
    "source hardpath.sh\n",
    "source run.sh "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![w](run.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relevant program is in :\n",
    "    /projects/speech/ASR/kaldi/src/featbin/copy-feats.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "which copy-feats\n",
    "/projects/speech/ASR/kaldi/src/featbin/copy-feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every function inside"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](featbin.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be several ways to do this, for example using the copy-feats, subset-feats or select-feats. But the easiest way might be simply using the head and cut method in shell script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "copy-feats scp:data/train_yesno/feats.scp  ark,t:- | head -n 10 | cut -d \" \" -f 1-7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0_0_0_0_1_1_1_1  [\n",
    "  48.9744 -14.08839 -0.1344485 4.717914 21.6918\n",
    "  53.68612 -10.14594 -1.394663 -2.119221 13.08845\n",
    "  55.30577 -10.31021 2.78328 6.130801 18.00465\n",
    "  56.4837 -16.38815 -2.418089 8.250131 5.304466\n",
    "  59.04967 -6.238433 -3.889265 -4.782257 1.989483\n",
    "  61.00519 -5.754362 -2.929802 -1.887652 9.401299\n",
    "  61.16815 -6.39979 -4.081158 -1.308731 0.9340096\n",
    "  61.98295 -7.206575 -1.714484 2.512146 2.200577\n",
    "  60.51631 -6.722504 -2.482053 -1.656084 4.4851"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![q](result.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompLing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
