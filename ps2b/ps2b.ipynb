{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Preparations\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.16'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import grammar, parse\n",
    "from nltk.parse.generate import generate\n",
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use Angela Liu's implementation from mapping the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dad\n",
      "----------------\n",
      "Domain = {'d', '3', '2', '1', 'a'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " 'adj': {('1', '2'), ('2', '1'), ('3', '2'), ('2', '3')},\n",
      " 'capital': {('1',)},\n",
      " 'char': {('3', 'd'), ('2', 'a'), ('1', 'd')},\n",
      " 'cons': {('d',)},\n",
      " 'glide': set(),\n",
      " 'le': {('1', '2'), ('1', '3'), ('2', '3')},\n",
      " 'vowel': {('a',)}}\n",
      "\n",
      "mAtch\n",
      "----------------\n",
      "Domain = {'c', 't', '3', 'h', 'm', '2', '5', '4', '1', 'a'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " '4': '4',\n",
      " '5': '5',\n",
      " 'adj': {('1', '2'),\n",
      "         ('2', '1'),\n",
      "         ('2', '3'),\n",
      "         ('3', '2'),\n",
      "         ('3', '4'),\n",
      "         ('4', '3'),\n",
      "         ('4', '5'),\n",
      "         ('5', '4')},\n",
      " 'capital': {('2',)},\n",
      " 'char': {('2', 'a'), ('4', 'c'), ('5', 'h'), ('1', 'm'), ('3', 't')},\n",
      " 'cons': {('h',), ('t',), ('c',), ('m',)},\n",
      " 'glide': set(),\n",
      " 'le': {('1', '2'),\n",
      "        ('1', '3'),\n",
      "        ('1', '4'),\n",
      "        ('1', '5'),\n",
      "        ('2', '3'),\n",
      "        ('2', '4'),\n",
      "        ('2', '5'),\n",
      "        ('3', '4'),\n",
      "        ('3', '5'),\n",
      "        ('4', '5')},\n",
      " 'vowel': {('a',)}}\n",
      "\n",
      "peRiLOuSy\n",
      "----------------\n",
      "Domain = {'8', 'e', 'y', '3', '6', '2', 'l', '5', 'u', '7', 'o', '4', '1', 'r', 'i', 'p', 's', '9'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " '4': '4',\n",
      " '5': '5',\n",
      " '6': '6',\n",
      " '7': '7',\n",
      " '8': '8',\n",
      " '9': '9',\n",
      " 'adj': {('1', '2'),\n",
      "         ('2', '1'),\n",
      "         ('2', '3'),\n",
      "         ('3', '2'),\n",
      "         ('3', '4'),\n",
      "         ('4', '3'),\n",
      "         ('4', '5'),\n",
      "         ('5', '4'),\n",
      "         ('5', '6'),\n",
      "         ('6', '5'),\n",
      "         ('6', '7'),\n",
      "         ('7', '6'),\n",
      "         ('7', '8'),\n",
      "         ('8', '7'),\n",
      "         ('8', '9'),\n",
      "         ('9', '8')},\n",
      " 'capital': {('5',), ('3',), ('6',), ('8',)},\n",
      " 'char': {('1', 'p'),\n",
      "          ('2', 'e'),\n",
      "          ('3', 'r'),\n",
      "          ('4', 'i'),\n",
      "          ('5', 'l'),\n",
      "          ('6', 'o'),\n",
      "          ('7', 'u'),\n",
      "          ('8', 's'),\n",
      "          ('9', 'y')},\n",
      " 'cons': {('r',), ('s',), ('l',), ('y',), ('p',)},\n",
      " 'glide': {('y',)},\n",
      " 'le': {('1', '2'),\n",
      "        ('1', '3'),\n",
      "        ('1', '4'),\n",
      "        ('1', '5'),\n",
      "        ('1', '6'),\n",
      "        ('1', '7'),\n",
      "        ('1', '8'),\n",
      "        ('1', '9'),\n",
      "        ('2', '3'),\n",
      "        ('2', '4'),\n",
      "        ('2', '5'),\n",
      "        ('2', '6'),\n",
      "        ('2', '7'),\n",
      "        ('2', '8'),\n",
      "        ('2', '9'),\n",
      "        ('3', '4'),\n",
      "        ('3', '5'),\n",
      "        ('3', '6'),\n",
      "        ('3', '7'),\n",
      "        ('3', '8'),\n",
      "        ('3', '9'),\n",
      "        ('4', '5'),\n",
      "        ('4', '6'),\n",
      "        ('4', '7'),\n",
      "        ('4', '8'),\n",
      "        ('4', '9'),\n",
      "        ('5', '6'),\n",
      "        ('5', '7'),\n",
      "        ('5', '8'),\n",
      "        ('5', '9'),\n",
      "        ('6', '7'),\n",
      "        ('6', '8'),\n",
      "        ('6', '9'),\n",
      "        ('7', '8'),\n",
      "        ('7', '9'),\n",
      "        ('8', '9')},\n",
      " 'vowel': {('u',), ('o',), ('e',), ('i',)}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List, Set\n",
    "\n",
    "def to_model_str(word: str, special_rels: List[Callable[[str], str]]=[]) -> str:\n",
    "    \"\"\"\n",
    "    Creates the string form of the model for the input word. This string is meant to be passed to `nltk.Valuation.fromstring`.\n",
    "    By default, the function will only add the relations mapping i => i for i from 1 to the length of `word` and a relation \n",
    "    mapping char => the set of tuples (i, word[i]). The `special_rels` function allows you to specify additional relations to \n",
    "    be added to the valuation string.\n",
    "    \n",
    "    :param word: The word to create a model string for.\n",
    "    :param special_rels: A list of functions that when called return a string of the form {relation_name} => {relation_contents}. Defaults to the empty list.\n",
    "    :returns: a string representing the model for word\n",
    "    \"\"\"\n",
    "    n = len(word)\n",
    "    model_str = []\n",
    "    char = []\n",
    "    for i in range(1, n+1):\n",
    "        model_str.append(f'{i} => {i}')\n",
    "        char.append((i, word[i-1]))\n",
    "    model_str.append(f'char => {set(char)}'.lower())\n",
    "    return '\\n'.join(model_str + [rel(word) for rel in special_rels]).replace(\"'\", \"\")\n",
    "# Angela Liu\n",
    "import re\n",
    "\n",
    "\n",
    "get_vowel = lambda w: f'vowel => {set(re.findall(r\"[AEIOUaeiou]\", w))}'.lower()\n",
    "get_cons = lambda w: 'cons => {}'.format(set(re.findall(r\"[^AEIOUaeiou\\W0-9]\", w))).lower()\n",
    "follows = lambda w: f'le => {set([(i+1,j+1) for i in range(len(w)) for j in range(i, len(w)) if i != j])}'\n",
    "get_capital = lambda w: f'capital => {set([m.span()[0] + 1 for m in re.finditer(r\"[A-Z]\", w)])}'\n",
    "# Angela Liu\n",
    "\n",
    "get_glide = lambda w: f'glide => {set(re.findall(r\"[YWyw]\", w))}'.lower()\n",
    "# is_final = lambda w: f'final => {set((len(w),))}'\n",
    "get_adj = lambda w: f'adj => {set([(i+1,j+1) for i in range(len(w)) for j in range(len(w)) if (i == j+1 or i == j-1)])}'\n",
    "# added\n",
    "\n",
    "def emptysets(val:nltk.sem.evaluate.Valuation):\n",
    "  val.update([(k,set()) for (k,v) in val.items() if v == 'set()'])\n",
    "\n",
    "words = ['Dad', 'mAtch', 'peRiLOuSy']\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_cons, follows, get_capital,get_glide, get_adj])) for w in words]\n",
    "for v in vals: emptysets(v)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]\n",
    "for w, m in zip(words, models):\n",
    "    print(f'{w}\\n----------------\\n{m}\\n')\n",
    "# Angela Liu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of the work:\n",
    "==="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Semantics of sentences about strings\n",
    "Computational Linguistics Spring 2023\n",
    "Problems Set 2\n",
    "```\n",
    "\n",
    "The text for this module is the NLTK book\n",
    "Chapter 9. Building Feature Based Grammars and\n",
    "Chapter 10. Analyzing the Meaning of Sentences\n",
    "\n",
    "See also lecture8_2023.ipynb and string_2023.ipynb\n",
    "\n",
    "The purpose of the assingnment is to develop feature-based grammars that include\n",
    "logical semantics, and to evaluate the adequacy of the semantics by computing\n",
    "truth in logically constructed models.  For instance, we want to be able to\n",
    "evaluate whether the sentence\n",
    "\n",
    "   every consonant is capitalized\n",
    "\n",
    "is true or false as description of the word\n",
    "\n",
    "   CINEMA\n",
    "\n",
    "or\n",
    "\n",
    "   Cinema\n",
    "\n",
    "or\n",
    "\n",
    "   CINEmA.\n",
    "\n",
    "In each problem n do these steps. The problem statement gives sentence sn. See\n",
    "Chapters 9 and 10 for the methodology.\n",
    "\n",
    "(i) Define a feature based grammar gn that includes all the words in sentence sn\n",
    "its lexicon.  The feature grammars will usually add a word and/or construction\n",
    "to a base grammar which will be similar to simple-sem.fcfg.  This base grammar\n",
    "will be distributed. (It will be helpful to figure out how to add a lexical item\n",
    "or production to a grammar in Python. Discuss the method for this on the forum.\n",
    "Or you can define the grammar from scratch.)\n",
    "\n",
    "(ii) Parse the sentenced and display the tree.\n",
    "\n",
    "(iii) Map sn to a logical formula fn by parsing with gn and extracting the\n",
    "semantics that annotates the root.\n",
    "\n",
    "(iv) Define a combination four words (serving as models) and the intuitive\n",
    "truth values of sentence sn as a description of the word.\n",
    "\n",
    "(v) Transform the four words into four models or valuations in the sense of\n",
    "Chapter 10. This can be done as in Lecture 8, or by using a function.\n",
    "Code for this may be shared and discussed on the forum.\n",
    "\n",
    "(vi) Evaluate formula fn in the four models to obtain four truth values. Compare them\n",
    "to the target truth values.\n",
    "\n",
    "Work individually, except that code for mapping a word to a valuation may be\n",
    "shared.  Post techinical questions and requests for hints on the forum.\n",
    "\n",
    "Notes\n",
    "The problems are selected so that quantifiers are used only in subject position.\n",
    "So it is not necessary (except perhaps in challenge problems) to apply the strategy\n",
    "from simple-sem.fcfg to fit quantified NPs into object positions.\n",
    "\n",
    "The words 'precedes' and 'follows' are interpreted in the sense of 'not necessarily\n",
    "immediately'.\n",
    "\n",
    "\n",
    "Problems\n",
    "=======\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. letter three is final\n",
    "\n",
    "   Define \"final\" in a way that works for words of any length. Don't include a\n",
    "   corresponding constant in the valutions. Decide what should happen with a words of\n",
    "   length one.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "A[SEM=<\\n. all m.-le(n,m)  >] -> 'final'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all m.-le(3,m)>]\n",
      "  (NP[SEM=<3>] letter three)\n",
      "  (VP[SEM=<\\n.all m.-le(n,m)>] is (A[SEM=<\\n.all m.-le(n,m)>] final)))\n"
     ]
    }
   ],
   "source": [
    "g6 = nltk.load_parser('h2.fcfg', trace=0, cache=False)\n",
    "s6 = 'letter three is final'\n",
    "s6_split = s6.split()\n",
    "for tree in g6.parse(s6_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](g6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all m.-le(3,m)\n"
     ]
    }
   ],
   "source": [
    "t6=next(g6.parse(s6_split))\n",
    "f6 = t6.label()['SEM']\n",
    "print(f6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e6 = [('emu',True),('batd',False),('cbjasaa',False),('awe',True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e6]\n",
    "truths = [e[1] for e in e6]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter three is final\n",
      "---------------\n",
      "emu\n",
      "True\n",
      "----------------\n",
      "batd\n",
      "False\n",
      "----------------\n",
      "cbjasaa\n",
      "False\n",
      "----------------\n",
      "awe\n",
      "True\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s6}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f6),a)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct! emu & awe has the third letter being the final\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "7. every vowel is adjacent to letter three\n",
    "\n",
    "   Include 'adjacent' in the grammar. Use the strategy with PP[to] to select the\n",
    "   preposition.  Either define the semantics of 'adjacent' in terms of the available\n",
    "   primitives, or add to the function that constructs valuations.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "VP[SEM=<?P(?Q)>] -> 'is' A[SEM=?P] PP[SEM=?Q]\n",
    "\n",
    "PP[SEM=?Q] -> 'to' NP[SEM=?Q]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all n.(exists c.(vowel(c) & char(n,c)) -> adj(3,n))>]\n",
      "  (DP[SEM=<\\Q.all n.(exists c.(vowel(c) & char(n,c)) -> Q(n))>]\n",
      "    (Det[SEM=<\\P Q.all n.(P(n) -> Q(n))>] every)\n",
      "    (N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vowel))\n",
      "  (VP[SEM=<\\n.adj(3,n)>]\n",
      "    is\n",
      "    (A[SEM=<\\m n.adj(m,n)>] adjacent)\n",
      "    (PP[SEM=<3>] to (NP[SEM=<3>] letter three))))\n"
     ]
    }
   ],
   "source": [
    "g7 = nltk.load_parser('h2.fcfg', trace=0, cache=False)\n",
    "s7 = 'every vowel is adjacent to letter three'\n",
    "s7_split = s7.split()\n",
    "for tree in g7.parse(s7_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](g7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all n.(exists c.(vowel(c) & char(n,c)) -> adj(3,n))\n"
     ]
    }
   ],
   "source": [
    "t7=next(g7.parse(s7_split))\n",
    "f7 = t7.label()['SEM']\n",
    "print(f7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "e7 = [('emuqe',False),('batd',True),('cbjas',True),('aweqwef',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e7]\n",
    "truths = [e[1] for e in e7]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows,get_adj])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every vowel is adjacent to letter three\n",
      "---------------\n",
      "emuqe\n",
      "False\n",
      "----------------\n",
      "batd\n",
      "True\n",
      "----------------\n",
      "cbjas\n",
      "True\n",
      "----------------\n",
      "aweqwef\n",
      "False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s7}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f7),a)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct!\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "8. every vowel that follows letter two is capitalized  \n",
    "   This has a subject relative clause . Methodology for the\n",
    "   semantics of subject relative clauses is in lecture8.ipynb.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "CP[SEM=?P] -> 'that' S[SEM=?P]/NP\n",
    "N[NUM=?n,SEM=<\\x.(?P(x) & ?Q(x))>] -> N[NUM=?n,SEM=?P] CP[SEM=?Q]\n",
    "NP/NP ->\n",
    "VP[NUM=?n,SEM=<\\y x.(?v(y)(x))>]/NP -> TV[NUM=?n,SEM=?v] NP/NP[SEM=?obj]\n",
    "S[SEM = <\\y.(?vp(y)(?subj))>]/NP -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]/NP\n",
    "S[SEM = <\\y.(?vp(y))>]/NP -> NP/NP VP[NUM=?n,SEM=?vp]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all n.((exists c.(vowel(c) & char(n,c)) & le(2,n)) -> capital(n))>]\n",
      "  (DP[SEM=<\\Q.all n.((exists c.(vowel(c) & char(n,c)) & le(2,n)) -> Q(n))>]\n",
      "    (Det[SEM=<\\P Q.all n.(P(n) -> Q(n))>] every)\n",
      "    (N[NUM=?n, SEM=<\\x.(exists c.(vowel(c) & char(x,c)) & le(2,x))>]\n",
      "      (N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vowel)\n",
      "      (CP[SEM=<\\y.le(2,y)>]\n",
      "        that\n",
      "        (S[SEM=<\\y.le(2,y)>]/NP[]\n",
      "          (NP[]/NP[] )\n",
      "          (VP[SEM=<\\n.le(2,n)>]\n",
      "            (TV[SEM=<\\m n.le(m,n)>] follows)\n",
      "            (NP[SEM=<2>] letter two))))))\n",
      "  (VP[SEM=<\\n.capital(n)>] is (A[SEM=<\\n.capital(n)>] capitalized)))\n"
     ]
    }
   ],
   "source": [
    "g8 = nltk.load_parser('h2.fcfg', trace=0\n",
    "                      , cache=False)\n",
    "s8 = 'every vowel that follows letter two is capitalized'\n",
    "s8_split = s8.split()\n",
    "for tree in g8.parse(s8_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](g8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all n.((exists c.(vowel(c) & char(n,c)) & le(2,n)) -> capital(n))\n"
     ]
    }
   ],
   "source": [
    "t8=next(g8.parse(s8_split))\n",
    "f8 = t8.label()['SEM']\n",
    "print(f8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "e8 = [('emUqE',True),('baTde',False),('cbJAs',True),('aweqwef',False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e8]\n",
    "truths = [e[1] for e in e8]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows,get_adj ,get_capital])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every vowel that follows letter two is capitalized\n",
      "---------------\n",
      "emUqE\n",
      "True\n",
      "----------------\n",
      "baTde\n",
      "False\n",
      "----------------\n",
      "cbJAs\n",
      "True\n",
      "----------------\n",
      "aweqwef\n",
      "False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s8}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f8),a)}\\n----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct!\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "9. some vowel immediately precedes letter three  \n",
    "   some vowel immediately follows letter three  \n",
    "\n",
    "  Define \"immediately\" in a way that works for both \"precedes\" and \"follows\".\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "\n",
    "TV[SEM=<\\m n.(le(m,n) & adj(m,n))>] -> 'immediately' 'follows'\n",
    "TV[SEM=<\\m n.(le(n,m) & adj(n,m))>] -> 'immediately' 'precedes'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists n.(exists c.(vowel(c) & char(n,c)) & le(n,3) & adj(n,3))>]\n",
      "  (DP[SEM=<\\Q.exists n.(exists c.(vowel(c) & char(n,c)) & Q(n))>]\n",
      "    (Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] some)\n",
      "    (N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vowel))\n",
      "  (VP[SEM=<\\n.(le(n,3) & adj(n,3))>]\n",
      "    (TV[SEM=<\\m n.(le(n,m) & adj(n,m))>] immediately precedes)\n",
      "    (NP[SEM=<3>] letter three)))\n"
     ]
    }
   ],
   "source": [
    "g9 = nltk.load_parser('h2.fcfg', trace=0\n",
    "                      , cache=False)\n",
    "s9 = 'some vowel immediately precedes letter three'\n",
    "s9_split = s9.split()\n",
    "for tree in g9.parse(s9_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists n.(exists c.(vowel(c) & char(n,c)) & le(3,n) & adj(3,n))>]\n",
      "  (DP[SEM=<\\Q.exists n.(exists c.(vowel(c) & char(n,c)) & Q(n))>]\n",
      "    (Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] some)\n",
      "    (N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vowel))\n",
      "  (VP[SEM=<\\n.(le(3,n) & adj(3,n))>]\n",
      "    (TV[SEM=<\\m n.(le(m,n) & adj(m,n))>] immediately follows)\n",
      "    (NP[SEM=<3>] letter three)))\n"
     ]
    }
   ],
   "source": [
    "g91 = nltk.load_parser('h2.fcfg', trace=0\n",
    "                      , cache=False)\n",
    "s91 = 'some vowel immediately follows letter three'\n",
    "s91_split = s91.split()\n",
    "for tree in g91.parse(s91_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](g9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists n.(exists c.(vowel(c) & char(n,c)) & le(n,3) & adj(n,3))\n"
     ]
    }
   ],
   "source": [
    "t9=next(g9.parse(s9_split))\n",
    "f9 = t9.label()['SEM']\n",
    "print(f9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "e9 = [('emUqE',False),('baTde',True),('cbJAs',False),('aeqwef',True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e9]\n",
    "truths = [e[1] for e in e9]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows,get_adj ,get_capital])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some vowel immediately precedes letter three\n",
      "---------------\n",
      "emUqE\n",
      "False\n",
      "----------------\n",
      "baTde\n",
      "True\n",
      "----------------\n",
      "cbJAs\n",
      "False\n",
      "----------------\n",
      "aeqwef\n",
      "True\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s9}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f9),a)}\\n----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct!\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "10. Post at least one challenge problem to PS2 challenge on the forum before\n",
    "   the target date for challenge problems.  Be creative rather than varying\n",
    "   challenge problems from others in mechanical ways. Include your challenge problem\n",
    "   here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` diff\n",
    "+Define \"symmetric\" as in the sentence below\n",
    "\n",
    "+every letter is symmetric. \n",
    "\n",
    "+the word symmetric means that the letter on some position is the same as the letter holding the same position only counted backwards of the word.\n",
    "+Put together, this sentence is referring to the situation where the word can be read backward and still lookes the same, AKA a palindrome.\n",
    "for example, abba, steponnopets, nisioisin are satisfied words.\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "11. Solve at least one challenge problem. When you solve it, post core\n",
    "   part of the result to ed.  Give your solution here in the format above. Don't pick\n",
    "   a problem that somebody else has solved.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define \"repeated\" as used in the sentence below.\n",
    "\n",
    "    Some consonant is repeated.\n",
    "\n",
    "Intended meaning: some consonant type (e.g. \"b/B\") occurs at least twice.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "\n",
    "A[SEM=<\\n. exists c.(char(n,c) & (exists m.(char(m,c) & m!=n)) )  >] -> 'repeated'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists n.(exists c.(-vowel(c) & char(n,c)) & exists c.(char(n,c) & exists m.(char(m,c) & -(m = n))))>]\n",
      "  (DP[SEM=<\\Q.exists n.(exists c.(-vowel(c) & char(n,c)) & Q(n))>]\n",
      "    (Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] some)\n",
      "    (N[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>] consonant))\n",
      "  (VP[SEM=<\\n.exists c.(char(n,c) & exists m.(char(m,c) & -(m = n)))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(char(n,c) & exists m.(char(m,c) & -(m = n)))>]\n",
      "      repeated)))\n"
     ]
    }
   ],
   "source": [
    "g11 = nltk.load_parser('h2.fcfg', trace=0\n",
    "                      , cache=False)\n",
    "s11 = 'some consonant is repeated'\n",
    "s11_split = s11.split()\n",
    "for tree in g11.parse(s11_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](g11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists n.(exists c.(-vowel(c) & char(n,c)) & exists c.(char(n,c) & exists m.(char(m,c) & -(m = n))))\n"
     ]
    }
   ],
   "source": [
    "t11=next(g11.parse(s11_split))\n",
    "f11 = t11.label()['SEM']\n",
    "print(f11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "e11 = [('Dad',True),('baTde',True),('cbJAs',False),('aeqwWef',True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e11]\n",
    "truths = [e[1] for e in e11]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows,get_adj ,get_capital])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some consonant is repeated\n",
      "---------------\n",
      "Dad\n",
      "True\n",
      "----------------\n",
      "baTde\n",
      "False\n",
      "----------------\n",
      "cbJAs\n",
      "False\n",
      "----------------\n",
      "aeqwWef\n",
      "True\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s11}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f11),a)}\\n----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*12. If you made a contribution to defining the function that maps word strings\n",
    "to valuations, describe it here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below is the function that maps word strings to valuations that i modified. This is still mostly based on Angela Liu's work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get_vowel = lambda w: f'vowel => {set(re.findall(r\"[AEIOUaeiou]\", w))}'.lower()\n",
    "# get_cons = lambda w: 'cons => {}'.format(set(re.findall(r\"[^AEIOUaeiou\\W0-9]\", w))).lower()\n",
    "# follows = lambda w: f'le => {set([(i+1,j+1) for i in range(len(w)) for j in range(i, len(w)) if i != j])}'\n",
    "# get_capital = lambda w: f'capital => {set([m.span()[0] + 1 for m in re.finditer(r\"[A-Z]\", w)])}'\n",
    "# get_glide = lambda w: f'glide => {set(re.findall(r\"[YWyw]\", w))}'.lower()\n",
    "# # is_final = lambda w: f'final => {set((len(w),))}'\n",
    "# get_adj = lambda w: f'adj => {set([(i+1,j+1) for i in range(len(w)) for j in range(len(w)) if (i == j+1 or i == j-1)])}'\n",
    "# # added\n",
    "\n",
    "# def emptysets(val:nltk.sem.evaluate.Valuation):\n",
    "#   val.update([(k,set()) for (k,v) in val.items() if v == 'set()'])\n",
    "\n",
    "# words = ['cat', 'mAtch', 'peRiLOuSy']\n",
    "# vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_cons, follows, get_capital,get_glide, get_adj])) for w in words]\n",
    "# for v in vals: emptysets(v)\n",
    "# models = [nltk.Model(val.domain, val) for val in vals]\n",
    "# for w, m in zip(words, models):\n",
    "#     print(f'{w}\\n----------------\\n{m}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompLing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efd08fb7d61c09f4aaea9e8ceb0bf572fefe064d17a4cedc1b735c081f854a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
