{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Preparations\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.16'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import grammar, parse\n",
    "from nltk.parse.generate import generate\n",
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# Grammar Rules\n",
      "S[SEM=<?subj(?vp)>] -> DP[SEM=?subj] VP[SEM=?vp]\n",
      "S[SEM=<?vp(?subj)>] -> NP[SEM=?subj] VP[SEM=?vp]\n",
      "S[SEM=<?vp1(?subj) & ?vp2(?subj)>] -> NP[SEM=?subj] VP[SEM=?vp1] 'and' VP[SEM=?vp2]\n",
      "DP[ SEM=<?X(?P)>] -> Det[SEM=?X] N[SEM=?P] \n",
      "VP[SEM=?Q] -> 'is' A[SEM=?Q]\n",
      "VP[SEM=?P] -> 'is' 'a' N[SEM=?P]\n",
      "# This is included for testing.\n",
      "VP[SEM=<\\x.offend(x)>] -> 'offends'\n",
      "# Transitive verb with individual object.\n",
      "VP[ SEM=<?R(?n)>] -> TV[SEM=?R] NP[SEM=?n]\n",
      "# Transitive verb with quantifier object.\n",
      "# The object is given minimal scope.\n",
      "VP[ SEM=<\\m.?X(\\n.(?R(n)(m)))>] -> TV[SEM=?R] DP[SEM=?X]\n",
      "# Lexical Rules\n",
      "A[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] -> 'vocalic'\n",
      "A[SEM=<\\n.exists c.((-vowel(c)) & char(n,c))>] -> 'consonantal'\n",
      "A[SEM=<\\n.exists c.(capital(n) & char(n,c))>] -> 'capitalized'\n",
      "A[SEM=<\\n. (n = 1) >] -> 'initial'\n",
      "A[SEM=<\\n. all m.-le(n,m)  >] -> 'final'\n",
      "Det[SEM=<\\P Q.all n.(P(n) -> Q(n))>] -> 'every'\n",
      "Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] -> 'a'\n",
      "Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] -> 'some'\n",
      "Det[SEM=<\\P Q.all n.(P(n) -> -Q(n))>] -> 'no'\n",
      "N[SEM=<\\n.char(n,leti)>] -> 'i'\n",
      "N[SEM=<\\n.char(n,lete)>] -> 'e'\n",
      "N[SEM=<\\n.char(n,letu)>] -> 'u'\n",
      "N[SEM=<\\n.char(n,letp)>] -> 'p'\n",
      "N[SEM=<\\n.char(n,lett)>] -> 't'\n",
      "N[SEM=<\\n.char(n,letk)>] -> 'k'\n",
      "N[SEM=<\\n.exists c.(glide(c) & char(n,c))>] -> 'glide'\n",
      "N[SEM=<\\n.exists c.char(n,c)>] -> 'letter'\n",
      "N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] -> 'vowel'\n",
      "N[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>] -> 'consonant'\n",
      "NP[SEM=<1>] -> 'letter' 'one'\n",
      "NP[SEM=<2>] -> 'letter' 'two'\n",
      "NP[SEM=<3>] -> 'letter' 'three'\n",
      "NP[SEM=<4>] -> 'letter' 'four'\n",
      "NP[SEM=<5>] -> 'letter' 'five'\n",
      "TV[SEM=<\\m n.le(m,n)>] -> 'follows'\n",
      "TV[SEM=<\\m n.le(n,m)>] -> 'precedes'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('h2.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists c.(vowel(c) & char(2,c))>]\n",
      "  (NP[SEM=<2>] letter two)\n",
      "  (VP[SEM=<\\n.exists c.(vowel(c) & char(n,c))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vocalic)))\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.load_parser('h2.fcfg', trace=0)\n",
    "sent = 'letter two is vocalic'.split()\n",
    "for tree in cp.parse(sent): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.png](1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use Angela Liu's implementation from mapping the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "----------------\n",
      "Domain = {'a', '2', '3', '1', 'c', 't'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " 'capital': set(),\n",
      " 'char': {('3', 't'), ('1', 'c'), ('2', 'a')},\n",
      " 'cons': {('t',), ('c',)},\n",
      " 'glide': set(),\n",
      " 'le': {('1', '3'), ('1', '2'), ('2', '3')},\n",
      " 'vowel': {('a',)}}\n",
      "\n",
      "mAtch\n",
      "----------------\n",
      "Domain = {'4', '5', 'a', '2', '3', '1', 'm', 'h', 'c', 't'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " '4': '4',\n",
      " '5': '5',\n",
      " 'capital': {('2',)},\n",
      " 'char': {('2', 'a'), ('5', 'h'), ('4', 'c'), ('3', 't'), ('1', 'm')},\n",
      " 'cons': {('h',), ('t',), ('c',), ('m',)},\n",
      " 'glide': set(),\n",
      " 'le': {('1', '2'),\n",
      "        ('1', '3'),\n",
      "        ('1', '4'),\n",
      "        ('1', '5'),\n",
      "        ('2', '3'),\n",
      "        ('2', '4'),\n",
      "        ('2', '5'),\n",
      "        ('3', '4'),\n",
      "        ('3', '5'),\n",
      "        ('4', '5')},\n",
      " 'vowel': {('a',)}}\n",
      "\n",
      "peRiLOuSy\n",
      "----------------\n",
      "Domain = {'u', '4', '6', 'r', '5', '2', 'o', '3', '1', 's', 'i', 'y', '9', 'l', '7', 'e', '8', 'p'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " '4': '4',\n",
      " '5': '5',\n",
      " '6': '6',\n",
      " '7': '7',\n",
      " '8': '8',\n",
      " '9': '9',\n",
      " 'capital': {('8',), ('3',), ('5',), ('6',)},\n",
      " 'char': {('1', 'p'),\n",
      "          ('2', 'e'),\n",
      "          ('3', 'r'),\n",
      "          ('4', 'i'),\n",
      "          ('5', 'l'),\n",
      "          ('6', 'o'),\n",
      "          ('7', 'u'),\n",
      "          ('8', 's'),\n",
      "          ('9', 'y')},\n",
      " 'cons': {('l',), ('p',), ('y',), ('r',), ('s',)},\n",
      " 'glide': {('y',)},\n",
      " 'le': {('1', '2'),\n",
      "        ('1', '3'),\n",
      "        ('1', '4'),\n",
      "        ('1', '5'),\n",
      "        ('1', '6'),\n",
      "        ('1', '7'),\n",
      "        ('1', '8'),\n",
      "        ('1', '9'),\n",
      "        ('2', '3'),\n",
      "        ('2', '4'),\n",
      "        ('2', '5'),\n",
      "        ('2', '6'),\n",
      "        ('2', '7'),\n",
      "        ('2', '8'),\n",
      "        ('2', '9'),\n",
      "        ('3', '4'),\n",
      "        ('3', '5'),\n",
      "        ('3', '6'),\n",
      "        ('3', '7'),\n",
      "        ('3', '8'),\n",
      "        ('3', '9'),\n",
      "        ('4', '5'),\n",
      "        ('4', '6'),\n",
      "        ('4', '7'),\n",
      "        ('4', '8'),\n",
      "        ('4', '9'),\n",
      "        ('5', '6'),\n",
      "        ('5', '7'),\n",
      "        ('5', '8'),\n",
      "        ('5', '9'),\n",
      "        ('6', '7'),\n",
      "        ('6', '8'),\n",
      "        ('6', '9'),\n",
      "        ('7', '8'),\n",
      "        ('7', '9'),\n",
      "        ('8', '9')},\n",
      " 'vowel': {('o',), ('u',), ('i',), ('e',)}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List, Set\n",
    "\n",
    "def to_model_str(word: str, special_rels: List[Callable[[str], str]]=[]) -> str:\n",
    "    \"\"\"\n",
    "    Creates the string form of the model for the input word. This string is meant to be passed to `nltk.Valuation.fromstring`.\n",
    "    By default, the function will only add the relations mapping i => i for i from 1 to the length of `word` and a relation \n",
    "    mapping char => the set of tuples (i, word[i]). The `special_rels` function allows you to specify additional relations to \n",
    "    be added to the valuation string.\n",
    "    \n",
    "    :param word: The word to create a model string for.\n",
    "    :param special_rels: A list of functions that when called return a string of the form {relation_name} => {relation_contents}. Defaults to the empty list.\n",
    "    :returns: a string representing the model for word\n",
    "    \"\"\"\n",
    "    n = len(word)\n",
    "    model_str = []\n",
    "    char = []\n",
    "    for i in range(1, n+1):\n",
    "        model_str.append(f'{i} => {i}')\n",
    "        char.append((i, word[i-1]))\n",
    "    model_str.append(f'char => {set(char)}'.lower())\n",
    "    return '\\n'.join(model_str + [rel(word) for rel in special_rels]).replace(\"'\", \"\")\n",
    "# Angela Liu\n",
    "import re\n",
    "\n",
    "\n",
    "get_vowel = lambda w: f'vowel => {set(re.findall(r\"[AEIOUaeiou]\", w))}'.lower()\n",
    "get_cons = lambda w: 'cons => {}'.format(set(re.findall(r\"[^AEIOUaeiou\\W0-9]\", w))).lower()\n",
    "follows = lambda w: f'le => {set([(i+1,j+1) for i in range(len(w)) for j in range(i, len(w)) if i != j])}'\n",
    "get_capital = lambda w: f'capital => {set([m.span()[0] + 1 for m in re.finditer(r\"[A-Z]\", w)])}'\n",
    "# Angela Liu\n",
    "\n",
    "get_glide = lambda w: f'glide => {set(re.findall(r\"[YWyw]\", w))}'.lower()\n",
    "# is_final = lambda w: f'final => {set((len(w),))}'\n",
    "# added\n",
    "\n",
    "def emptysets(val:nltk.sem.evaluate.Valuation):\n",
    "  val.update([(k,set()) for (k,v) in val.items() if v == 'set()'])\n",
    "\n",
    "words = ['cat', 'mAtch', 'peRiLOuSy']\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_cons, follows, get_capital,get_glide])) for w in words]\n",
    "for v in vals: emptysets(v)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]\n",
    "for w, m in zip(words, models):\n",
    "    print(f'{w}\\n----------------\\n{m}\\n')\n",
    "# Angela Liu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of the work:\n",
    "==="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Semantics of sentences about strings\n",
    "Computational Linguistics Spring 2023\n",
    "Problems Set 2\n",
    "```\n",
    "\n",
    "The text for this module is the NLTK book\n",
    "Chapter 9. Building Feature Based Grammars and\n",
    "Chapter 10. Analyzing the Meaning of Sentences\n",
    "\n",
    "See also lecture8_2023.ipynb and string_2023.ipynb\n",
    "\n",
    "The purpose of the assingnment is to develop feature-based grammars that include\n",
    "logical semantics, and to evaluate the adequacy of the semantics by computing\n",
    "truth in logically constructed models.  For instance, we want to be able to\n",
    "evaluate whether the sentence\n",
    "\n",
    "   every consonant is capitalized\n",
    "\n",
    "is true or false as description of the word\n",
    "\n",
    "   CINEMA\n",
    "\n",
    "or\n",
    "\n",
    "   Cinema\n",
    "\n",
    "or\n",
    "\n",
    "   CINEmA.\n",
    "\n",
    "In each problem n do these steps. The problem statement gives sentence sn. See\n",
    "Chapters 9 and 10 for the methodology.\n",
    "\n",
    "(i) Define a feature based grammar gn that includes all the words in sentence sn\n",
    "its lexicon.  The feature grammars will usually add a word and/or construction\n",
    "to a base grammar which will be similar to simple-sem.fcfg.  This base grammar\n",
    "will be distributed. (It will be helpful to figure out how to add a lexical item\n",
    "or production to a grammar in Python. Discuss the method for this on the forum.\n",
    "Or you can define the grammar from scratch.)\n",
    "\n",
    "(ii) Parse the sentenced and display the tree.\n",
    "\n",
    "(iii) Map sn to a logical formula fn by parsing with gn and extracting the\n",
    "semantics that annotates the root.\n",
    "\n",
    "(iv) Define a combination four words (serving as models) and the intuitive\n",
    "truth values of sentence sn as a description of the word.\n",
    "\n",
    "(v) Transform the four words into four models or valuations in the sense of\n",
    "Chapter 10. This can be done as in Lecture 8, or by using a function.\n",
    "Code for this may be shared and discussed on the forum.\n",
    "\n",
    "(vi) Evaluate formula fn in the four models to obtain four truth values. Compare them\n",
    "to the target truth values.\n",
    "\n",
    "Work individually, except that code for mapping a word to a valuation may be\n",
    "shared.  Post techinical questions and requests for hints on the forum.\n",
    "\n",
    "Notes\n",
    "The problems are selected so that quantifiers are used only in subject position.\n",
    "So it is not necessary (except perhaps in challenge problems) to apply the strategy\n",
    "from simple-sem.fcfg to fit quantified NPs into object positions.\n",
    "\n",
    "The words 'precedes' and 'follows' are interpreted in the sense of 'not necessarily\n",
    "immediately'.\n",
    "\n",
    "\n",
    "Problems\n",
    "=======\n",
    "\n",
    "1. letter two is consonantal   \n",
    "Base your analysis on 'letter two is vocalic', which is covered by the base grammar.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "A[SEM=<\\n.exists c.(consonant(c) & char(n,c))>] -> 'consonantal'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists c.(-vowel(c) & char(2,c))>]\n",
      "  (NP[SEM=<2>] letter two)\n",
      "  (VP[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>] consonantal)))\n"
     ]
    }
   ],
   "source": [
    "g1 = nltk.load_parser('h2.fcfg', trace=0)\n",
    "s1 = 'letter two is consonantal'\n",
    "s1_split = s1.split()\n",
    "for tree in g1.parse(s1_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists c.(-vowel(c) & char(2,c))\n"
     ]
    }
   ],
   "source": [
    "t1=next(g1.parse(s1_split))\n",
    "f1 = t1.label()['SEM']\n",
    "print(f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = [('emu',True),('bat',False),('cat',False),('aka',True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e1]\n",
    "truths = [e[1] for e in e1]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter two is consonantal\n",
      "---------------\n",
      "emu\n",
      "True\n",
      "----------------\n",
      "bat\n",
      "False\n",
      "----------------\n",
      "cat\n",
      "False\n",
      "----------------\n",
      "aka\n",
      "True\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s1}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f1),a)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct! emu & aka has the second letter being consonants\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. letter three is final\n",
    "\n",
    "   Define \"final\" in a way that works for words of any length. Don't include a\n",
    "   corresponding constant in the valutions. Decide what should happen with a words of\n",
    "   length one.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "A[SEM=<\\n. all m.-le(n,m)  >] -> 'final'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all m.-le(3,m)>]\n",
      "  (NP[SEM=<3>] letter three)\n",
      "  (VP[SEM=<\\n.all m.-le(n,m)>] is (A[SEM=<\\n.all m.-le(n,m)>] final)))\n"
     ]
    }
   ],
   "source": [
    "g6 = nltk.load_parser('h2.fcfg', trace=0, cache=False)\n",
    "s6 = 'letter three is final'\n",
    "s6_split = s6.split()\n",
    "for tree in g6.parse(s6_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6](6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all m.-le(3,m)\n"
     ]
    }
   ],
   "source": [
    "t6=next(g6.parse(s6_split))\n",
    "f6 = t6.label()['SEM']\n",
    "print(f6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e6 = [('emu',True),('batd',False),('cbja',False),('awe',True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e6]\n",
    "truths = [e[1] for e in e6]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter three is final\n",
      "---------------\n",
      "emu\n",
      "True\n",
      "----------------\n",
      "batd\n",
      "False\n",
      "----------------\n",
      "cbja\n",
      "False\n",
      "----------------\n",
      "awe\n",
      "True\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s6}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f6),a)}\\n----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct! emu & aka has the second letter being consonants\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "7. every vowel is adjacent to letter three\n",
    "\n",
    "   Include 'adjacent' in the grammar. Use the strategy with PP[to] to select the\n",
    "   preposition.  Either define the semantics of 'adjacent' in terms of the available\n",
    "   primitives, or add to the function that constructs valuations.\n",
    "\n",
    "8. every vowel that follows letter two is capitalized\n",
    "   This has a subject relative clause . Methodology for the\n",
    "   semantics of subject relative clauses is in lecture8.ipynb.\n",
    "\n",
    "9. some vowel immediately precedes letter three\n",
    "   some vowel immediately follows letter three\n",
    "\n",
    "  Define \"immediately\" in a way that works for both \"precedes\" and \"follows\".\n",
    "\n",
    "10. Post at least one challenge problem to PS2 challenge on the forum before\n",
    "   the target date for challenge problems.  Be creative rather than varying\n",
    "   challenge problems from others in mechanical ways. Include your challenge problem\n",
    "   here.\n",
    "\n",
    "11. Solve at least one challenge problem. When you solve it, post core\n",
    "   part of the result to ed.  Give your solution here in the format above. Don't pick\n",
    "   a problem that somebody else has solved.\n",
    "\n",
    "*12. If you made a contribution to defining the function that maps word strings\n",
    "to valuations, describe it here.\n",
    "\n",
    "Work individually, except that code for mapping a word to a valuation may be\n",
    "shared.  Post techinical questions and requests for hints on the forum.\n",
    "\n",
    "Notes\n",
    "The problems are selected so that quantifiers are used only in subject position.\n",
    "So it is not necessary (except perhaps in challenge problems) to apply the strategy\n",
    "from simple-sem.fcfg to fit quantified NPs into object positions.\n",
    "\n",
    "The words 'precedes' and 'follows' are interpreted in the sense of 'not necessarily\n",
    "immediately'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompLing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efd08fb7d61c09f4aaea9e8ceb0bf572fefe064d17a4cedc1b735c081f854a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
