{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "military-pathology",
   "metadata": {},
   "source": [
    "## Advanced Fst\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5948271-62ad-484f-bed2-9de05ed4a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hfst_dev as hfst\n",
    "import graphviz\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff1cf3-166d-40db-971a-fee1236d6b69",
   "metadata": {},
   "source": [
    "## Replacement rules\n",
    "#### Standard replacement rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "round-sampling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: H Pages: 1 -->\n",
       "<svg width=\"198pt\" height=\"93pt\"\n",
       " viewBox=\"0.00 0.00 198.29 93.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 89.2)\">\n",
       "<title>H</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-89.2 194.29,-89.2 194.29,4 -4,4\"/>\n",
       "<!-- q0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"35\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"35\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q0 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M23.13,-49.69C21.83,-60.63 25.79,-70.2 35,-70.2 40.76,-70.2 44.46,-66.46 46.11,-60.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"49.59,-61.41 46.77,-51.2 42.61,-60.94 49.59,-61.41\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-74\" font-family=\"Times,serif\" font-size=\"14.00\">u, k, t, p, ?? </text>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"164.2\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"164.2\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.2\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q1 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M61.43,-26.1C80.07,-26.1 105.63,-26.1 126.48,-26.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.29,-29.6 136.29,-26.1 126.29,-22.6 126.29,-29.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.6\" y=\"-29.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.53,-14.01C134.1,-11.17 126.98,-8.55 120.1,-7.1 102.27,-3.34 96.93,-3.34 79.1,-7.1 75.87,-7.78 72.59,-8.71 69.36,-9.81\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.11,-6.54 60.08,-13.45 70.67,-13.06 68.11,-6.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.6\" y=\"-10.9\" font-family=\"Times,serif\" font-size=\"14.00\">??, u:o </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.32,-49.69C151.03,-60.63 154.99,-70.2 164.2,-70.2 169.95,-70.2 173.66,-66.46 175.31,-60.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.79,-61.41 175.97,-51.2 171.8,-60.94 178.79,-61.41\"/>\n",
       "<text text-anchor=\"middle\" x=\"164.2\" y=\"-74\" font-family=\"Times,serif\" font-size=\"14.00\">o, k, t, p </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x111f27430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons = hfst.regex('p | t | k')\n",
    "defs = {\"C\":cons}\n",
    "uo = hfst.regex('u -> o || o C* _ ',definitions=defs)\n",
    "defs['uo'] = uo\n",
    "uo.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "later-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: H Pages: 1 -->\n",
       "<svg width=\"318pt\" height=\"60pt\"\n",
       " viewBox=\"0.00 0.00 318.19 60.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 56.2)\">\n",
       "<title>H</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-56.2 314.19,-56.2 314.19,4 -4,4\"/>\n",
       "<!-- q0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"19.5\" cy=\"-26.1\" rx=\"19.5\" ry=\"19.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"19.5\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q0</text>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"105.49\" cy=\"-26.1\" rx=\"19.5\" ry=\"19.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.49\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q1</text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M39.14,-26.1C49.51,-26.1 62.66,-26.1 74.44,-26.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.1,-29.6 84.1,-26.1 74.1,-22.6 74.1,-29.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5\" y=\"-29.9\" font-family=\"Times,serif\" font-size=\"14.00\">b </text>\n",
       "</g>\n",
       "<!-- q2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q2</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"191.49\" cy=\"-26.1\" rx=\"19.5\" ry=\"19.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"191.49\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q2</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125.14,-26.1C135.5,-26.1 148.66,-26.1 160.44,-26.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"160.1,-29.6 170.1,-26.1 160.1,-22.6 160.1,-29.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.49\" y=\"-29.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>q3</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"284.09\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"284.09\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"284.09\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q3 </text>\n",
       "</g>\n",
       "<!-- q2&#45;&gt;q3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q2&#45;&gt;q3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211.26,-26.1C221.4,-26.1 234.26,-26.1 246.3,-26.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.96,-29.6 255.96,-26.1 245.96,-22.6 245.96,-29.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.49\" y=\"-29.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11218bb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bou = hfst.regex('[{bou} .o. uo].l',\n",
    "                         definitions=defs)\n",
    "bou.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6364cae4-ed0d-4be6-b78b-9fda8dec2c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boo']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bou.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabf14c5-27bc-48d3-9414-ee93a98c1d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bokotu']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bokutu = hfst.regex('[{bokutu} .o. uo].l',\n",
    "                         definitions=defs)\n",
    "list(bokutu.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ce130-8b85-4735-9d52-92bd1ca42f42",
   "metadata": {},
   "source": [
    "The rationale is that the second `u` is not in the input\n",
    "context of an `o`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impaired-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "uo2 = hfst.regex('u -> o // o C* _ ',definitions=defs)\n",
    "defs['uo2'] = uo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intense-swing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bokoto']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bokutu = hfst.regex('[{bokutu} .o. uo2].l',\n",
    "                         definitions=defs)\n",
    "list(bokutu.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7789898e-c69c-4ca3-a7cb-4d6e550024e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: H Pages: 1 -->\n",
       "<svg width=\"185pt\" height=\"93pt\"\n",
       " viewBox=\"0.00 0.00 185.20 93.20\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 89.2)\">\n",
       "<title>H</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-89.2 181.2,-89.2 181.2,4 -4,4\"/>\n",
       "<!-- q0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"35\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"35\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q0 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M25.35,-50.59C24.56,-61.15 27.78,-70.2 35,-70.2 39.4,-70.2 42.32,-66.84 43.74,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.21,-62.34 44.53,-52.09 40.24,-61.78 47.21,-62.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-74\" font-family=\"Times,serif\" font-size=\"14.00\">u, k, t, p, ?? </text>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"139.2\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"139.2\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q1 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M61.52,-26.1C73.6,-26.1 88.23,-26.1 101.47,-26.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.13,-29.6 111.13,-26.1 101.13,-22.6 101.13,-29.6\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.1\" y=\"-29.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M115.53,-14.01C109.1,-11.17 101.98,-8.55 95.1,-7.1 86.45,-5.28 77.27,-6.57 68.79,-9.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.69,-5.85 59.57,-12.67 70.16,-12.4 67.69,-5.85\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.1\" y=\"-10.9\" font-family=\"Times,serif\" font-size=\"14.00\">?? </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.54,-50.59C128.75,-61.15 131.97,-70.2 139.2,-70.2 143.6,-70.2 146.51,-66.84 147.94,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.41,-62.34 148.73,-52.09 144.43,-61.78 151.41,-62.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-74\" font-family=\"Times,serif\" font-size=\"14.00\">o, k, t, p, u:o </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11218b820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uo2.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95448a4-8e61-4021-b157-3b5f73367958",
   "metadata": {},
   "source": [
    "The `//` replacement rule matches the left context\n",
    "on the lower side.  This makes vowel harmony propagate.\n",
    "Vowel harmony in natural languages can be of either kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd9f3c3-8950-4eb3-9a47-e37525673e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "uo3 = hfst.regex('u -> o \\/ o C* _ C* o',definitions=defs)\n",
    "defs['uo3'] = uo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96001846-6a40-4c2c-b26c-8a5f18eb60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uo4 = hfst.regex('u -> o || o C* _ C* o',definitions=defs)\n",
    "defs['uo4'] = uo4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e25a06-49a9-4703-8146-b540791a3f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bokoto']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bokuto = hfst.regex('[{bokuto} .o. uo3].l',\n",
    "                         definitions=defs)\n",
    "list(bokuto.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39346e28-a613-4608-8ef3-f8eaf1d01d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bokopopopoto']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bokuputo = hfst.regex('[{bokupupuputo} .o. uo3].l',\n",
    "                         definitions=defs)\n",
    "list(bokuputo.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79eb3af7-c06b-4f5d-a697-0254ac82eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: H Pages: 1 -->\n",
       "<svg width=\"288pt\" height=\"187pt\"\n",
       " viewBox=\"0.00 0.00 287.89 186.60\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 182.6)\">\n",
       "<title>H</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-182.6 283.89,-182.6 283.89,4 -4,4\"/>\n",
       "<!-- q0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"35\" cy=\"-53.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"35\" cy=\"-53.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-49.4\" font-family=\"Times,serif\" font-size=\"14.00\">q0 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M25.35,-77.59C24.56,-88.15 27.78,-97.2 35,-97.2 39.4,-97.2 42.32,-93.84 43.74,-88.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.21,-89.34 44.53,-79.09 40.24,-88.78 47.21,-89.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-101\" font-family=\"Times,serif\" font-size=\"14.00\">u, k, t, p, ?? </text>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"139.2\" cy=\"-91.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"139.2\" cy=\"-91.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-87.4\" font-family=\"Times,serif\" font-size=\"14.00\">q1 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.96,-62.01C73.03,-66.87 89.44,-72.97 103.84,-78.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.37,-81.51 112.97,-81.72 104.81,-74.95 102.37,-81.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.1\" y=\"-78.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.33,-70.91C114.98,-63.16 105.55,-55.2 95.1,-51.1 87.99,-48.31 80.02,-47.31 72.3,-47.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.2,-43.79 62.41,-47.84 72.59,-50.78 72.2,-43.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.1\" y=\"-54.9\" font-family=\"Times,serif\" font-size=\"14.00\">?? </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.54,-115.59C128.75,-126.15 131.97,-135.2 139.2,-135.2 143.6,-135.2 146.51,-131.84 147.94,-126.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.41,-127.34 148.73,-117.09 144.43,-126.78 151.41,-127.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-139\" font-family=\"Times,serif\" font-size=\"14.00\">o, k, t, p </text>\n",
       "</g>\n",
       "<!-- q2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q2</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"249.39\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"249.39\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q2 </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.09,-77.94C177.78,-68.52 199.16,-55.68 216.71,-45.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.46,-48.16 225.23,-40.01 214.86,-42.16 218.46,-48.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.29\" y=\"-68.9\" font-family=\"Times,serif\" font-size=\"14.00\">u </text>\n",
       "</g>\n",
       "<!-- q3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>q3</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"249.39\" cy=\"-126.1\" rx=\"19.5\" ry=\"19.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-122.4\" font-family=\"Times,serif\" font-size=\"14.00\">q3</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.6,-87.76C177.91,-87.07 192.73,-87.63 205.29,-92.1 213.02,-94.84 220.41,-99.58 226.83,-104.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.48,-107.25 234.32,-111.17 229.07,-101.97 224.48,-107.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.29\" y=\"-95.9\" font-family=\"Times,serif\" font-size=\"14.00\">u:o </text>\n",
       "</g>\n",
       "<!-- q2&#45;&gt;q0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>q2&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.05,-28C189.85,-30.67 129.9,-36.11 79.1,-44.1 76.8,-44.46 74.43,-44.86 72.05,-45.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.63,-41.81 62.48,-47.15 72.96,-48.68 71.63,-41.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-42.9\" font-family=\"Times,serif\" font-size=\"14.00\">?? </text>\n",
       "</g>\n",
       "<!-- q2&#45;&gt;q2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>q2&#45;&gt;q2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.18,-50.59C238.35,-61.15 241.75,-70.2 249.39,-70.2 254.05,-70.2 257.13,-66.84 258.64,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.11,-62.36 259.47,-52.09 255.13,-61.76 262.11,-62.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-74\" font-family=\"Times,serif\" font-size=\"14.00\">u, k, t, p </text>\n",
       "</g>\n",
       "<!-- q3&#45;&gt;q1 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>q3&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.05,-121.12C216.94,-117.48 198.94,-112.28 183.29,-107.1 180.41,-106.14 177.43,-105.12 174.45,-104.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.82,-100.84 165.22,-100.72 173.43,-107.42 175.82,-100.84\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.29\" y=\"-117.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q3&#45;&gt;q3 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>q3&#45;&gt;q3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.71,-143.46C237.55,-153.83 240.78,-163.6 249.39,-163.6 254.64,-163.6 257.89,-159.97 259.14,-154.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.64,-154.95 259.09,-144.97 255.64,-154.99 262.64,-154.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-167.4\" font-family=\"Times,serif\" font-size=\"14.00\">k, t, p, u:o </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11218b910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uo3.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1926b2e7-c600-45b9-a90b-0987309c450f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.1.0 (20230121.1956)\n",
       " -->\n",
       "<!-- Title: H Pages: 1 -->\n",
       "<svg width=\"283pt\" height=\"187pt\"\n",
       " viewBox=\"0.00 0.00 283.49 186.60\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 182.6)\">\n",
       "<title>H</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-182.6 279.49,-182.6 279.49,4 -4,4\"/>\n",
       "<!-- q0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>q0</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"35\" cy=\"-53.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"35\" cy=\"-53.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-49.4\" font-family=\"Times,serif\" font-size=\"14.00\">q0 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M25.35,-77.59C24.56,-88.15 27.78,-97.2 35,-97.2 39.4,-97.2 42.32,-93.84 43.74,-88.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.21,-89.34 44.53,-79.09 40.24,-88.78 47.21,-89.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"35\" y=\"-101\" font-family=\"Times,serif\" font-size=\"14.00\">u, k, t, p, ?? </text>\n",
       "</g>\n",
       "<!-- q1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>q1</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"139.2\" cy=\"-91.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"139.2\" cy=\"-91.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-87.4\" font-family=\"Times,serif\" font-size=\"14.00\">q1 </text>\n",
       "</g>\n",
       "<!-- q0&#45;&gt;q1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>q0&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.96,-62.01C73.03,-66.87 89.44,-72.97 103.84,-78.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.37,-81.51 112.97,-81.72 104.81,-74.95 102.37,-81.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.1\" y=\"-78.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.33,-70.91C114.98,-63.16 105.55,-55.2 95.1,-51.1 87.99,-48.31 80.02,-47.31 72.3,-47.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"72.2,-43.79 62.41,-47.84 72.59,-50.78 72.2,-43.79\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.1\" y=\"-54.9\" font-family=\"Times,serif\" font-size=\"14.00\">?? </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.54,-115.59C128.75,-126.15 131.97,-135.2 139.2,-135.2 143.6,-135.2 146.51,-131.84 147.94,-126.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.41,-127.34 148.73,-117.09 144.43,-126.78 151.41,-127.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-139\" font-family=\"Times,serif\" font-size=\"14.00\">o, k, t, p </text>\n",
       "</g>\n",
       "<!-- q2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>q2</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"249.39\" cy=\"-26.1\" rx=\"22.18\" ry=\"22.18\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"249.39\" cy=\"-26.1\" rx=\"26.2\" ry=\"26.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-22.4\" font-family=\"Times,serif\" font-size=\"14.00\">q2 </text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.09,-77.94C177.78,-68.52 199.16,-55.68 216.71,-45.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.46,-48.16 225.23,-40.01 214.86,-42.16 218.46,-48.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.29\" y=\"-68.9\" font-family=\"Times,serif\" font-size=\"14.00\">u </text>\n",
       "</g>\n",
       "<!-- q3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>q3</title>\n",
       "<ellipse fill=\"yellow\" stroke=\"black\" cx=\"249.39\" cy=\"-126.1\" rx=\"19.5\" ry=\"19.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-122.4\" font-family=\"Times,serif\" font-size=\"14.00\">q3</text>\n",
       "</g>\n",
       "<!-- q1&#45;&gt;q3 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>q1&#45;&gt;q3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.6,-87.76C177.91,-87.07 192.73,-87.63 205.29,-92.1 213.02,-94.84 220.41,-99.58 226.83,-104.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"224.48,-107.25 234.32,-111.17 229.07,-101.97 224.48,-107.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.29\" y=\"-95.9\" font-family=\"Times,serif\" font-size=\"14.00\">u:o </text>\n",
       "</g>\n",
       "<!-- q2&#45;&gt;q0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>q2&#45;&gt;q0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M223.05,-28C189.85,-30.67 129.9,-36.11 79.1,-44.1 76.8,-44.46 74.43,-44.86 72.05,-45.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"71.63,-41.81 62.48,-47.15 72.96,-48.68 71.63,-41.81\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2\" y=\"-42.9\" font-family=\"Times,serif\" font-size=\"14.00\">u, ?? </text>\n",
       "</g>\n",
       "<!-- q2&#45;&gt;q2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>q2&#45;&gt;q2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.18,-50.59C238.35,-61.15 241.75,-70.2 249.39,-70.2 254.05,-70.2 257.13,-66.84 258.64,-61.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.11,-62.36 259.47,-52.09 255.13,-61.76 262.11,-62.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-74\" font-family=\"Times,serif\" font-size=\"14.00\">k, t, p </text>\n",
       "</g>\n",
       "<!-- q3&#45;&gt;q1 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>q3&#45;&gt;q1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.05,-121.12C216.94,-117.48 198.94,-112.28 183.29,-107.1 180.41,-106.14 177.43,-105.12 174.45,-104.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.82,-100.84 165.22,-100.72 173.43,-107.42 175.82,-100.84\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.29\" y=\"-117.9\" font-family=\"Times,serif\" font-size=\"14.00\">o </text>\n",
       "</g>\n",
       "<!-- q3&#45;&gt;q3 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>q3&#45;&gt;q3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M239.71,-143.46C237.55,-153.83 240.78,-163.6 249.39,-163.6 254.64,-163.6 257.89,-159.97 259.14,-154.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"262.64,-154.95 259.09,-144.97 255.64,-154.99 262.64,-154.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.39\" y=\"-167.4\" font-family=\"Times,serif\" font-size=\"14.00\">k, t, p </text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x111f83430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uo4.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183774af-e284-4f27-85d8-f05779c3db54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ubokopopopotou']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bokuputo = hfst.regex('[{ubokupupuputou} .o. uo3].l',\n",
    "                         definitions=defs)\n",
    "list(bokuputo.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1bd1eb-1ebc-4941-9c91-5797f5f9116e",
   "metadata": {},
   "source": [
    "It's not what I expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5eadf-a859-4ca6-84f4-08e85513fb3a",
   "metadata": {},
   "source": [
    "#### Epenthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b11fe7-538e-4029-9f37-1d002564eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel = hfst.regex('i | u | o')\n",
    "defs['V'] = vowel\n",
    "ep = hfst.regex('[..] -> i || C _ C',\n",
    "                         definitions=defs)\n",
    "defs['ep'] = ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a3dc782-ccd8-4da3-bc02-c698e70cc748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kutitipipip']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = hfst.regex('[{kuttppp} .o. ep].l',\n",
    "                         definitions=defs)\n",
    "list(result.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac226ca2-d737-4a62-8362-7b71d7f7bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "syl = hfst.regex('[a +] -> A || C _',\n",
    "                         definitions=defs)\n",
    "defs['syl'] = syl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b323cf6-c6b5-4b6a-ae12-091f267ba1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kAaat', 'kAat', 'kAt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = hfst.regex('[{kaaat} .o. syl].l',\n",
    "                         definitions=defs)\n",
    "list(result.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97049dc-0fdd-4cf3-b360-f487e1b7a3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79547b27-2a8a-45f1-932d-61f968c45161",
   "metadata": {},
   "outputs": [],
   "source": [
    "syl2 = hfst.regex('[a +] @-> A || C _',\n",
    "                         definitions=defs)\n",
    "defs['syl2'] = syl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a03bc1a2-66b9-4486-b321-280219a62cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kAt']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = hfst.regex('[{kaaat} .o. syl2].l',\n",
    "                         definitions=defs)\n",
    "list(result.extract_paths().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bf8f0-2b0e-4623-b80e-7742cfa4287b",
   "metadata": {},
   "source": [
    "### Load English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2286185-62c8-4fdd-a694-78dba4ef36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "istream = hfst.HfstInputStream('/local/teach/cl23/H/H3/English')\n",
    "English = istream.read()\n",
    "istream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b93302d4-bfb5-4e60-a76a-323b6b23cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "defs['English'] = English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ac79e1e-21f3-4d2e-904d-f7fd4d68f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_input(x,n=8,cycles=3):\n",
    "        x2 = x.copy()\n",
    "        x2.input_project()\n",
    "        x2.minimize()\n",
    "        return(random.sample(set(x2.extract_paths(max_cycles=3).keys()),n))\n",
    "def sample_output(x,n=8,cycles=3):\n",
    "        x2 = x.copy()\n",
    "        x2.output_project()\n",
    "        x2.minimize()\n",
    "        return(random.sample(set(x2.extract_paths(max_cycles=3).keys()),n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79d324a8-5205-4076-a17c-5a293127b5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['framin|g',\n",
       " 'dinapoli',\n",
       " 'sorkin',\n",
       " 'filip|pel|lo',\n",
       " 'emporia',\n",
       " 'markel|l',\n",
       " 's|houlde|r',\n",
       " 'fe|arin|g']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input(English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d6797c3-bc97-40e8-9a1c-398929efc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vow0 = hfst.regex('[AH0| IH0| ER0| IY0| OW0| AA0| EH0| UW0| AE0| AO0| AY0| EY0| AW0| UH0| OY0]')\n",
    "Vow1 = hfst.regex('[EH1| AE1| AA1| IH1| IY1| EY1| OW1| AO1| AY1| AH1| UW1| ER1| AW1| UH1| OY1]')\n",
    "Vow2 = hfst.regex('[EH2| EY2| AE2| AY2| AA2| IH2| OW2| IY2| AO2| UW2| AH2| AW2| ER2| UH2| OY2]')\n",
    "Gli = hfst.regex('[R| W| Y]')\n",
    "Nas = hfst.regex('[N| M| NG]')\n",
    "Obs = hfst.regex('[S| L| T| K| D| Z| B| P| F| G| V| HH| SH| JH| CH| TH| DH| ZH]')\n",
    "Phone = hfst.regex('[AH0| N| S| L| T| R| K| D| IH0| M| Z| ER0| IY0| B| EH1| P| AE1| AA1| IH1| F| G| V| IY1| NG| HH| EY1| W| SH| OW1| OW0| AO1| AY1| AH1| UW1| JH| Y| CH| AA0| ER1| EH2| EY2| AE2| AY2| AA2| EH0| IH2| TH| AW1| OW2| UW0| IY2| AO2| AE0| UH1| AO0| AY0| UW2| AH2| EY0| OY1| AW2| DH| ZH| ER2| UH2| AW0| UH0| OY2| OY0]')\n",
    "defs[\"Vow0\"]=Vow0\n",
    "defs[\"Vow1\"]=Vow1\n",
    "defs[\"Vow2\"]=Vow2\n",
    "defs[\"Vow\"]=Vow\n",
    "defs[\"Gli\"]=Gli\n",
    "defs[\"Nas\"]=Nas\n",
    "defs[\"Obs\"]=Obs\n",
    "defs[\"Phone\"]=Phone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d91e003-abc4-4fc4-86d0-bec64276dff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hoc|k', 'sahl', 's|hep|p', 'feet', 'ja|ys', 's|hap', 'he|at|h', 'fake']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvc = hfst.regex('English .o. [Obs Vow1 Obs]',\n",
    "                         definitions=defs)\n",
    "sample_input(cvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e68d15d3-821f-42ba-905e-29f44cd0dd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sikh', 'hu|rl', 'lees', 'to|yed', 'to|ol', 'seip|p', 'pa|il|le', 'poac|h']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input(cvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "754c473d-bdbb-40f1-a640-3c55418fe240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BAW1T', 'FAW1T', 'HHAH1SH', 'PUH1SH', 'PAE1CH', 'BEY1L', 'SIY1F', 'KIH1SH']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_output(cvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6373928-54b5-4477-a5d4-6173680bdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vow = hfst.regex('[Vow0 | Vow1 | Vow2]')\n",
    "defs['Vow'] = Vow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "866ecd2e-c35e-4196-9a29-c1098fa2646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VowAA = hfst.regex('[AA0 | AA1 | AA2]')\n",
    "VowAE = hfst.regex('[AE0 | AE1 | AE2]')\n",
    "VowAH = hfst.regex('[AH0 | AH1 | AH2]')\n",
    "VowAO = hfst.regex('[AO0 | AO1 | AO2]')\n",
    "VowAW = hfst.regex('[AW0 | AW1 | AW2]')\n",
    "VowAY = hfst.regex('[AY0 | AY1 | AY2]')\n",
    "VowEH = hfst.regex('[EH0 | EH1 | EH2]')\n",
    "VowER = hfst.regex('[ER0 | ER1 | ER2]')\n",
    "VowEY = hfst.regex('[EY0 | EY1 | EY2]')\n",
    "VowIH = hfst.regex('[IH0 | IH1 | IH2]')\n",
    "VowIY = hfst.regex('[IY0 | IY1 | IY2]')\n",
    "VowOW = hfst.regex('[OW0 | OW1 | OW2]')\n",
    "VowOY = hfst.regex('[OY0 | OY1 | OY2]')\n",
    "VowUH = hfst.regex('[UH0 | UH1 | UH2]')\n",
    "VowUW = hfst.regex('[UW0 | UW1 | UW2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c03baf9e-f8a0-4293-9e06-650e968616f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "defs[\"Vow0\"]=Vow0\n",
    "defs[\"Vow1\"]=Vow1\n",
    "defs[\"Vow2\"]=Vow2\n",
    "defs[\"Vow\"]=Vow\n",
    "defs[\"Gli\"]=Gli\n",
    "defs[\"Nas\"]=Nas\n",
    "defs[\"Obs\"]=Obs\n",
    "defs[\"Phone\"]=Phone\n",
    "defs[\"VowAA\"]=VowAA\n",
    "defs[\"VowAE\"]=VowAE\n",
    "defs[\"VowAH\"]=VowAH\n",
    "defs[\"VowAO\"]=VowAO\n",
    "defs[\"VowAW\"]=VowAW\n",
    "defs[\"VowAY\"]=VowAY\n",
    "defs[\"VowEH\"]=VowEH\n",
    "defs[\"VowER\"]=VowER\n",
    "defs[\"VowEY\"]=VowEY\n",
    "defs[\"VowIH\"]=VowIH\n",
    "defs[\"VowIY\"]=VowIY\n",
    "defs[\"VowOW\"]=VowOW\n",
    "defs[\"VowOY\"]=VowOY\n",
    "defs[\"VowUH\"]=VowUH\n",
    "defs[\"VowUW\"]=VowUW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6ce8363d-5358-44db-a554-56b9525a7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cic = hfst.regex('English .o. [Obs VowIH Obs]',\n",
    "                         definitions=defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ee513ce-88b5-4714-ab78-9b4c20afcc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sic|k', 'fit|he', 's|chic|k', 'kis', 'pil|le', 'bib|b', 'sig', 'dig']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input(cic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "73c77668-c5ac-4725-99de-092257bd6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvc = hfst.regex('English .o. [Obs Vow1 Obs]',\n",
    "                         definitions=defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be3f33af-185a-47f4-b73f-331eb4bcf1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t|huot', 'pe|rt|h', 'dase', 'zos|s', 'co|op', 'haac|ke', 'vic', 'sis']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input(cvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4f37bc3d-813d-4764-97be-d7b5e4666771",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvc = hfst.regex('English .o. [Obs Vow1 Obs]',\n",
    "                         definitions=defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9940b8a9-69ec-4c9b-b46b-da8489e81e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = hfst.regex('[..] -> \" \" || Phone _ Phone',\n",
    "                         definitions=defs)\n",
    "defs[\"space\"]=space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6cf7a105-aece-46c6-82d9-52597c008ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvcs = hfst.regex('English .o. [Obs Vow1 Obs]',\n",
    "                         definitions=defs)\n",
    "cvcs.minimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d8515ba-83cc-4fae-91d4-a6f74241656d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.0, ((\"'\", '@_EPSILON_SYMBOL_@'), ('t', 'T'), ('i', 'IH1'), ('l', 'L'))),\n",
       " (0.0, (('b', 'B'), ('e|r', 'ER1'), ('c', 'K'), ('h', '@_EPSILON_SYMBOL_@'))),\n",
       " (0.0, (('c', 'K'), ('o|u', 'AW1'), ('s', 'S'), ('e', '@_EPSILON_SYMBOL_@'))),\n",
       " (0.0, (('c', 'S'), ('.', 'IY1'), (\"'|s\", 'Z'))),\n",
       " (0.0, (('c|h', 'CH'), ('a', 'AA1'), ('z|z', 'Z'))),\n",
       " (0.0, (('c|h', 'CH'), ('e|r', 'ER1'), ('t', 'T'))),\n",
       " (0.0, (('c|h', 'CH'), ('o|w', 'AW1'), ('s', 'Z'))),\n",
       " (0.0,\n",
       "  (('c|h', 'SH'), ('a|i', 'EY1'), ('s', 'Z'), ('e', '@_EPSILON_SYMBOL_@'))),\n",
       " (0.0, (('c|h', 'SH'), ('e', 'EH1'), ('f', 'F'))),\n",
       " (0.0, (('c|h', 'SH'), ('i', 'IY1'), ('c', 'K'))),\n",
       " (0.0, (('c|z', 'CH'), ('e', 'EH1'), ('c', 'K'), ('h', '@_EPSILON_SYMBOL_@'))),\n",
       " (0.0, (('c|z', 'CH'), ('y', 'IH1'), ('z', 'Z'))))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvc.extract_paths(max_number=12,output='raw',random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c404eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "can = hfst.regex('${can} .o. English ',\n",
    "                         definitions=defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f5ce14b8-9538-48e9-a961-a75508cbeda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on HfstTransducer in module libhfst_dev object:\n",
      "\n",
      "class HfstTransducer(builtins.object)\n",
      " |  HfstTransducer(*args)\n",
      " |  \n",
      " |  A synchronous finite-state transducer.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __del__ lambda self\n",
      " |  \n",
      " |  __getattr__ lambda self, name\n",
      " |  \n",
      " |  __init__(self, *args)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__ = _swig_repr(self)\n",
      " |  \n",
      " |  __setattr__ lambda self, name, value\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      An AT&T representation of the transducer.\n",
      " |      \n",
      " |      Defined for print command. An example:\n",
      " |      \n",
      " |           >>> print(hfst.regex('[foo:bar::2]+'))\n",
      " |           0       1       foo     bar     2.000000\n",
      " |           1       1       foo     bar     2.000000\n",
      " |           1       0.000000 Todo\n",
      " |      Works only for small transducers.\n",
      " |  \n",
      " |  compare(self, arg2, harmonize=True)\n",
      " |      Whether this transducer and *another* are equivalent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `another` :\n",
      " |          The compared transducer.\n",
      " |      \n",
      " |      pre: *self* and *another* must have the same implementation type.\n",
      " |      \n",
      " |      Two transducers are equivalent iff they accept the same input/output string\n",
      " |      pairs with the same weights and the same alignments.\n",
      " |      \n",
      " |      note: For weighted transducers, the function often returns false negatives due\n",
      " |          to weight precision issues.\n",
      " |  \n",
      " |  compose(self, tr, harmonize=True)\n",
      " |      Compose this transducer with *another*.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `another` :\n",
      " |          The second argument in the composition. Not modified.\n",
      " |  \n",
      " |  compose_intersect(self, v, invert=False, harmonize=True)\n",
      " |      Compose this transducer with the intersection of transducers in *v*.\n",
      " |      \n",
      " |      If *invert* is true, then compose the intersection of the transducers in *v*\n",
      " |      with this transducer.\n",
      " |      \n",
      " |      The algorithm used by this function is faster than intersecting all transducers\n",
      " |      one by one and then composing this transducer with the intersection.\n",
      " |      \n",
      " |      pre: The transducers in *v* are deterministic and epsilon-free.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `v` :\n",
      " |          A tuple of transducers.\n",
      " |      * `invert` :\n",
      " |          Whether the intersection of the transducers in *v* is composed with this\n",
      " |          transducer.\n",
      " |  \n",
      " |  concatenate(self, tr, harmonize=True)\n",
      " |      Concatenate this transducer with *another*.\n",
      " |  \n",
      " |  conjunct(self, t, harmonize=True)\n",
      " |      Alias for intersect.\n",
      " |      \n",
      " |      See also: hfst.HfstTransducer.intersect\n",
      " |  \n",
      " |  convert(self, impl)\n",
      " |      Convert the transducer into an equivalent transducer in format *type*.\n",
      " |      \n",
      " |      If a weighted transducer is converted into an unweighted one, all weights are\n",
      " |      lost. In the reverse case, all weights are initialized to the semiring's one.\n",
      " |      \n",
      " |      A transducer of type hfst.ImplementationType.SFST_TYPE, hfst.ImplementationType.TROPICAL_OPENFST_TYPE,\n",
      " |      hfst.ImplementationType.LOG_OPENFST_TYPE or hfst.ImplementationType.FOMA_TYPE can be converted into an\n",
      " |      hfst.ImplementationType.HFST_OL_TYPE or hfst.ImplementationType.HFST_OLW_TYPE transducer, but an\n",
      " |      hfst.ImplementationType.HFST_OL_TYPE or hfst.ImplementationType.HFST_OLW_TYPE transducer cannot be\n",
      " |      converted to any other type.\n",
      " |      \n",
      " |      note: For conversion between HfstIterableTransducer and HfstTransducer, see\n",
      " |          hfst.HfstTransducer.__init__ and hfst.HfstIterableTransducer.__init__\n",
      " |  \n",
      " |  copy(self)\n",
      " |      Return a deep copy of the transducer.\n",
      " |  \n",
      " |  cross_product(self, another, harmonize=True)\n",
      " |      Make cross product of this transducer with *another*.\n",
      " |      \n",
      " |      It pairs every string of this with every string of *another*. If strings are not\n",
      " |      the same length, epsilon padding will be added in the end of the shorter string.\n",
      " |      \n",
      " |      pre: Both transducers must be automata, i.e. map strings onto themselves.\n",
      " |  \n",
      " |  determinize(self)\n",
      " |      Determinize the transducer.\n",
      " |      \n",
      " |      Determinizing a transducer yields an equivalent transducer that has no state\n",
      " |      with two or more transitions whose input:output symbol pairs are the same.\n",
      " |  \n",
      " |  disjunct(self, tr, harmonize=True)\n",
      " |      Disjunct this transducer with *another*.\n",
      " |  \n",
      " |  eliminate_flag(self, f)\n",
      " |      Eliminate flag diacritic *symbol* from the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `symbol` :\n",
      " |          The flag to be eliminated. TODO: explain more.\n",
      " |      \n",
      " |      An equivalent transducer with no flags *symbol*.\n",
      " |  \n",
      " |  eliminate_flags(self)\n",
      " |      Eliminate flag diacritics listed in *symbols* from the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `symbols` :\n",
      " |          The flags to be eliminated. TODO: explain more.\n",
      " |      \n",
      " |      An equivalent transducer with no flags listed in *symbols*.\n",
      " |  \n",
      " |  extract_longest_paths(self, **kwargs)\n",
      " |      Extract longest paths of the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `kwargs` :\n",
      " |          Possible parameters and their default values are: obey_flags=True,\n",
      " |          output='dict'\n",
      " |      * `obey_flags` :\n",
      " |          Whether flag diacritics are obeyed. The default is True.\n",
      " |      * `output` :\n",
      " |          Possible values are 'dict', 'text' and 'raw', 'dict' being the default.\n",
      " |  \n",
      " |  extract_paths(self, **kwargs)\n",
      " |      Extract paths that are recognized by the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `kwargs` :\n",
      " |          Arguments recognized are filter_flags, max_cycles, max_number, obey_flags,\n",
      " |          output, random.\n",
      " |      * `filter_flags` :\n",
      " |          Whether flags diacritics are filtered out from the result (default True).\n",
      " |      * `max_cycles` :\n",
      " |          Indicates how many times a cycle will be followed, with negative numbers\n",
      " |          indicating unlimited (default -1 i.e. unlimited).\n",
      " |      * `max_number` :\n",
      " |          The total number of resulting strings is capped at this value, with 0 or\n",
      " |          negative indicating unlimited (default -1 i.e. unlimited).\n",
      " |      * `obey_flags` :\n",
      " |          Whether flag diacritics are validated (default True).\n",
      " |      * `output` :\n",
      " |          Output format. Values recognized: 'text' (as a string, separated by\n",
      " |          newlines), 'raw' (a dictionary that maps each input string into a list of\n",
      " |          tuples of an output string and a weight), 'dict' (a dictionary that maps\n",
      " |          each input string into a tuple of tuples of an output string and a weight,\n",
      " |          the default).\n",
      " |      * `random` :\n",
      " |          Whether result strings are fetched randomly (default False).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      The extracted strings. *output* controls how they are represented.\n",
      " |      \n",
      " |      pre: The transducer must be acyclic, if both *max_number* and *max_cycles* have\n",
      " |      unlimited values. Else a hfst.exceptions.TransducerIsCyclicException will be\n",
      " |      thrown.\n",
      " |      \n",
      " |      An example:\n",
      " |      \n",
      " |      >>> tr = hfst.regex('a:b+ (a:c+)')\n",
      " |      >>> print(tr)\n",
      " |      0       1       a       b       0.000000\n",
      " |      1       1       a       b       0.000000\n",
      " |      1       2       a       c       0.000000\n",
      " |      1       0.000000\n",
      " |      2       2       a       c       0.000000\n",
      " |      2       0.000000\n",
      " |      \n",
      " |      >>> print(tr.extract_paths(max_cycles=1, output='text'))\n",
      " |      a:b     0\n",
      " |      aa:bb   0\n",
      " |      aaa:bbc 0\n",
      " |      aaaa:bbcc       0\n",
      " |      aa:bc   0\n",
      " |      aaa:bcc 0\n",
      " |      \n",
      " |      >>> print(tr.extract_paths(max_number=4, output='text'))\n",
      " |      a:b     0\n",
      " |      aa:bc   0\n",
      " |      aaa:bcc 0\n",
      " |      aaaa:bccc       0\n",
      " |      \n",
      " |      >>> print(tr.extract_paths(max_cycles=1, max_number=4, output='text'))\n",
      " |      a:b     0\n",
      " |      aa:bb   0\n",
      " |      aa:bc   0\n",
      " |      aaa:bcc 0\n",
      " |      \n",
      " |      Exceptions\n",
      " |      ----------\n",
      " |      * `TransducerIsCyclicException` :\n",
      " |      \n",
      " |      See also: hfst.HfstTransducer.n_best\n",
      " |  \n",
      " |  extract_shortest_paths(self, **kwargs)\n",
      " |      Extract shortest paths of the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `kwargs` :\n",
      " |          Possible parameters and their default values are: obey_flags=True.\n",
      " |      * `output` :\n",
      " |          Possible values are 'dict', 'text' and 'raw', 'dict' being the default.\n",
      " |  \n",
      " |  get_alphabet(self)\n",
      " |      Get the alphabet of the transducer.\n",
      " |      \n",
      " |      The alphabet is defined as the set of symbols known to the transducer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A tuple of strings.\n",
      " |  \n",
      " |  get_name(self)\n",
      " |      Get the name of the transducer.\n",
      " |      \n",
      " |      See also: set_name\n",
      " |  \n",
      " |  get_properties(self)\n",
      " |      Get all properties from the transducer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A dictionary whose keys are properties and whose values are the values of those\n",
      " |      properties.\n",
      " |  \n",
      " |  get_property(self, property)\n",
      " |      Get arbitrary string propert *property*.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `property` :\n",
      " |          The name of the property whose value is returned. get_property('name') works\n",
      " |          like get_name().\n",
      " |  \n",
      " |  get_type(self)\n",
      " |      The implementation type of the transducer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      hfst.ImplementationType\n",
      " |  \n",
      " |  has_flag_diacritics(self)\n",
      " |      Whether the transducer has flag diacritics in its transitions.\n",
      " |  \n",
      " |  input_project(self)\n",
      " |      Extract the input language of the transducer.\n",
      " |      \n",
      " |      All transition symbol pairs *isymbol:osymbol* are changed to *isymbol:isymbol*.\n",
      " |  \n",
      " |  insert_freely(self, *args)\n",
      " |      Freely insert a transition or a transducer into the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `ins` :\n",
      " |          The transition or transducer to be inserted.\n",
      " |      \n",
      " |      If *ins* is a transition, i.e. a 2-tuple of strings: A transition is added to\n",
      " |      each state in this transducer. The transition leads from that state to itself\n",
      " |      with input and output symbols defined by *ins*. The weight of the transition is\n",
      " |      zero.\n",
      " |      \n",
      " |      If *ins* is an hfst.HfstTransducer: A copy of *ins* is attached with epsilon\n",
      " |      transitions to each state of this transducer. After the operation, for each\n",
      " |      state S in this transducer, there is an epsilon transition that leads from state\n",
      " |      S to the initial state of *ins*, and for each final state of *ins*, there is an\n",
      " |      epsilon transition that leads from that final state to state S in this\n",
      " |      transducer. The weights of the final states in *ins* are copied to the epsilon\n",
      " |      transitions leading to state S.\n",
      " |  \n",
      " |  insert_to_alphabet(self, arg2)\n",
      " |      Explicitly insert *symbol* to the alphabet of the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `symbol` :\n",
      " |          The symbol (string) to be inserted.\n",
      " |      \n",
      " |      note: Usually this function is not needed since new symbols are added to the\n",
      " |          alphabet by default.\n",
      " |  \n",
      " |  intersect(self, tr, harmonize=True)\n",
      " |      Intersect this transducer with *another*.\n",
      " |  \n",
      " |  invert(self)\n",
      " |      Swap the input and output symbols of each transition in the transducer.\n",
      " |  \n",
      " |  is_automaton(self)\n",
      " |      Whether each transition in the transducer has equivalent input and output\n",
      " |      symbols.\n",
      " |      \n",
      " |      note: Transition with hfst.UNKNOWN on both sides IS NOT a transition with\n",
      " |          equivalent input and output symbols.\n",
      " |      \n",
      " |      note: Transition with hfst.IDENTITY on both sides IS a transition with\n",
      " |          equivalent input and output symbols.\n",
      " |  \n",
      " |  is_cyclic(self)\n",
      " |      Whether the transducer is cyclic.\n",
      " |  \n",
      " |  is_infinitely_ambiguous(self)\n",
      " |      Whether the transducer is infinitely ambiguous.\n",
      " |      \n",
      " |      A transducer is infinitely ambiguous if there exists an input that will yield\n",
      " |      infinitely many results, i.e. there are input epsilon loops that are traversed\n",
      " |      with that input.\n",
      " |  \n",
      " |  is_lookup_infinitely_ambiguous(self, arg2)\n",
      " |      Whether lookup of path *input* will have infinite results.\n",
      " |      \n",
      " |      Currently, this function will return whether the transducer is infinitely\n",
      " |      ambiguous on any lookup path found in the transducer, i.e. the argument *input*\n",
      " |      is ignored.\n",
      " |      \n",
      " |      Todo\n",
      " |      Do not ignore the argument *input*\n",
      " |  \n",
      " |  lenient_composition(self, another, harmonize=True)\n",
      " |      Perform a lenient composition on this transducer and *another*.\n",
      " |      \n",
      " |      TODO: explain more.\n",
      " |  \n",
      " |  longest_path_size(self, obey_flags=True)\n",
      " |      Get length of longest path of the transducer.\n",
      " |  \n",
      " |  lookup(self, input, **kwargs)\n",
      " |      Lookup string *input*.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `input` :\n",
      " |          The input. A string or a pre-tokenized tuple of symbols (i.e. a tuple of strings).\n",
      " |      * `kwargs` :\n",
      " |          Possible parameters and their default values are: obey_flags=True,\n",
      " |          max_number=-1, time_cutoff=0.0, output='tuple'\n",
      " |      * `obey_flags` :\n",
      " |          Whether flag diacritics are obeyed. Always True for HFST_OL(W)_TYPE transducers.\n",
      " |      * `show_flags` :\n",
      " |          Whether flag diacritics are shown when output is 'text' or 'tuple'. Defaults to False.\n",
      " |      * `max_number` :\n",
      " |          Maximum number of results returned, defaults to -1, i.e. infinity.\n",
      " |      * `time_cutoff` :\n",
      " |          How long the function can search for results before returning, expressed in\n",
      " |          seconds. Defaults to 0.0, i.e. infinitely. Always 0.0 for transducers that are\n",
      " |          not of HFST_OL(W)_TYPE.\n",
      " |      * `output` :\n",
      " |          Possible values are 'tuple', 'text' and 'raw', 'tuple' being the default.\n",
      " |      \n",
      " |      Note: This function has an efficient implementation only for optimized lookup format\n",
      " |      (hfst.ImplementationType.HFST_OL_TYPE or hfst.ImplementationType.HFST_OLW_TYPE). Other formats perform the\n",
      " |      lookup via composition. Consider converting the transducer to optimized lookup format\n",
      " |      or to a HfstIterableTransducer. Conversion to HFST_OL(W)_TYPE might take a while but the\n",
      " |      lookup is fast. Conversion to HfstIterableTransducer is quick but lookup is slower.\n",
      " |  \n",
      " |  lookup_optimize(self)\n",
      " |      Optimize the transducer for lookup.\n",
      " |      \n",
      " |      This effectively converts the transducer into hfst.ImplementationType.HFST_OL_TYPE.\n",
      " |  \n",
      " |  minimize(self)\n",
      " |      Minimize the transducer.\n",
      " |      \n",
      " |      Minimizing a transducer yields an equivalent transducer with the smallest number\n",
      " |      of states.\n",
      " |      \n",
      " |      Bug\n",
      " |      OpenFst's minimization algorithm seems to add epsilon transitions to weighted\n",
      " |      transducers?\n",
      " |  \n",
      " |  minus(self, t, harmonize=True)\n",
      " |      Alias for subtract.\n",
      " |      \n",
      " |      See also: hfst.HfstTransducer.subtract\n",
      " |  \n",
      " |  n_best(self, n)\n",
      " |      Extract *n* best paths of the transducer.\n",
      " |      \n",
      " |      In the case of a weighted transducer (hfst.ImplementationType.TROPICAL_OPENFST_TYPE or\n",
      " |      hfst.ImplementationType.LOG_OPENFST_TYPE), best paths are defined as paths with the lowest\n",
      " |      weight. In the case of an unweighted transducer (hfst.ImplementationType.SFST_TYPE or\n",
      " |      hfst.ImplementationType.FOMA_TYPE), the function returns random paths.\n",
      " |      \n",
      " |      This function is not implemented for hfst.ImplementationType.FOMA_TYPE or\n",
      " |      hfst.ImplementationType.SFST_TYPE. If this function is called by an HfstTransducer of type\n",
      " |      hfst.ImplementationType.FOMA_TYPE or hfst.ImplementationType.SFST_TYPE, it is converted to\n",
      " |      hfst.ImplementationType.TROPICAL_OPENFST_TYPE, paths are extracted and it is converted back\n",
      " |      to hfst.ImplementationType.FOMA_TYPE or hfst.ImplementationType.SFST_TYPE. If HFST is not linked to\n",
      " |      OpenFst library, an hfst.exceptions.ImplementationTypeNotAvailableException is\n",
      " |      thrown.\n",
      " |  \n",
      " |  number_of_arcs(self)\n",
      " |      The number of transitions in the transducer.\n",
      " |  \n",
      " |  number_of_states(self)\n",
      " |      The number of states in the transducer.\n",
      " |  \n",
      " |  optionalize(self)\n",
      " |      Disjunct the transducer with an epsilon transducer.\n",
      " |  \n",
      " |  output_project(self)\n",
      " |      Extract the output language of the transducer.\n",
      " |      \n",
      " |      All transition symbol pairs *isymbol:osymbol* are changed to *osymbol:osymbol*.\n",
      " |  \n",
      " |  priority_union(self, another)\n",
      " |      Make priority union of this transducer with *another*.\n",
      " |      \n",
      " |      For the operation t1.priority_union(t2), the result is a union of t1 and t2,\n",
      " |      except that whenever t1 and t2 have the same string on left side, the path in t2\n",
      " |      overrides the path in t1.\n",
      " |      \n",
      " |      Example\n",
      " |      \n",
      " |           Transducer 1 (t1):\n",
      " |           a : a\n",
      " |           b : b\n",
      " |      \n",
      " |           Transducer 2 (t2):\n",
      " |           b : B\n",
      " |           c : C\n",
      " |      \n",
      " |           Result ( t1.priority_union(t2) ):\n",
      " |           a : a\n",
      " |           b : B\n",
      " |           c : C For more information, read fsmbook.\n",
      " |  \n",
      " |  prune(self)\n",
      " |      Make transducer coaccessible.\n",
      " |      \n",
      " |      A transducer is coaccessible iff there is a path from every state to a final\n",
      " |      state.\n",
      " |  \n",
      " |  push_weights_to_end(self)\n",
      " |      Push weights towards final state(s).\n",
      " |      \n",
      " |      If the HfstTransducer is of unweighted type (hfst.ImplementationType.SFST_TYPE or\n",
      " |      hfst.ImplementationType.FOMA_TYPE), nothing is done.\n",
      " |      \n",
      " |      An example:\n",
      " |      \n",
      " |           >>> import hfst\n",
      " |           >>> tr = hfst.regex('[a::1 a:b::0.3 (b::0)]::0.7;')\n",
      " |           >>> tr.push_weights_to_end()\n",
      " |           >>> print(tr)\n",
      " |           0       1       a       a       0.000000\n",
      " |           1       2       a       b       0.000000\n",
      " |           2       3       b       b       0.000000\n",
      " |           2       2.000000\n",
      " |           3       2.000000\n",
      " |      \n",
      " |      See also: hfst.HfstTransducer.push_weights_to_start\n",
      " |  \n",
      " |  push_weights_to_start(self)\n",
      " |      Push weights towards initial state.\n",
      " |      \n",
      " |      If the HfstTransducer is of unweighted type (hfst.ImplementationType.SFST_TYPE or\n",
      " |      hfst.ImplementationType.FOMA_TYPE), nothing is done.\n",
      " |      \n",
      " |      An example:\n",
      " |      \n",
      " |           >>> import hfst\n",
      " |           >>> tr = hfst.regex('[a::1 a:b::0.3 (b::0)]::0.7;')\n",
      " |           >>> tr.push_weights_to_start()\n",
      " |           >>> print(tr)\n",
      " |           0       1       a       a       2.000000\n",
      " |           1       2       a       b       0.000000\n",
      " |           2       3       b       b       0.000000\n",
      " |           2       0.000000\n",
      " |           3       0.000000\n",
      " |      \n",
      " |      See also: hfst.HfstTransducer.push_weights_to_end\n",
      " |  \n",
      " |  read_all_from_file(filename_)\n",
      " |      Read all binary transducers from file *filename_*.\n",
      " |  \n",
      " |  read_from_file(filename_)\n",
      " |      Read a binary transducer from file *filename_*.\n",
      " |  \n",
      " |  remove_epsilons(self)\n",
      " |      Remove all *epsilon:epsilon* transitions from the transducer so that the\n",
      " |      resulting transducer is equivalent to the original one.\n",
      " |  \n",
      " |  remove_from_alphabet(self, arg2)\n",
      " |      Remove *symbol* from the alphabet of the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `symbol` :\n",
      " |          The symbol (string) to be removed.\n",
      " |      \n",
      " |      pre: *symbol* does not occur in any transition of the transducer.\n",
      " |      \n",
      " |      note: Use with care, removing a symbol that occurs in a transition of the\n",
      " |          transducer can have unexpected results.\n",
      " |  \n",
      " |  remove_optimization(self)\n",
      " |      Remove lookup optimization.\n",
      " |      \n",
      " |      This effectively converts transducer (back) into default fst type.\n",
      " |  \n",
      " |  repeat_n(self, n)\n",
      " |      A concatenation of *n* transducers.\n",
      " |  \n",
      " |  repeat_n_minus(self, n)\n",
      " |      A concatenation of N transducers where N is any number from zero to *n*,\n",
      " |      inclusive.\n",
      " |  \n",
      " |  repeat_n_plus(self, n)\n",
      " |      A concatenation of N transducers where N is any number from *n* to infinity,\n",
      " |      inclusive.\n",
      " |  \n",
      " |  repeat_n_to_k(self, n, k)\n",
      " |      A concatenation of N transducers where N is any number from *n* to *k*,\n",
      " |      inclusive.\n",
      " |  \n",
      " |  repeat_plus(self)\n",
      " |      A concatenation of N transducers where N is any number from one to infinity.\n",
      " |  \n",
      " |  repeat_star(self)\n",
      " |      A concatenation of N transducers where N is any number from zero to infinity.\n",
      " |  \n",
      " |  reverse(self)\n",
      " |      Reverse the transducer.\n",
      " |      \n",
      " |      A reverted transducer accepts the string 'n(0) n(1) ... n(N)' iff the original\n",
      " |      transducer accepts the string 'n(N) n(N-1) ... n(0)'\n",
      " |  \n",
      " |  set_final_weights(self, weight, increment=False)\n",
      " |      Set the weights of all final states to *weight*.\n",
      " |      \n",
      " |      If the HfstTransducer is of unweighted type (hfst.ImplementationType.SFST_TYPE or\n",
      " |      hfst.ImplementationType.FOMA_TYPE), nothing is done.\n",
      " |  \n",
      " |  set_name(self, name)\n",
      " |      Rename the transducer *name*.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `name` :\n",
      " |          The name of the transducer.\n",
      " |      \n",
      " |      See also: get_name\n",
      " |  \n",
      " |  set_property(self, property, value)\n",
      " |      Set arbitrary string property *property* to *value*.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `property` :\n",
      " |          A string naming the property.\n",
      " |      * `value` :\n",
      " |          A string expressing the value of *property*.\n",
      " |      \n",
      " |      set_property('name', 'name of the transducer') equals set_name('name of the\n",
      " |      transducer').\n",
      " |      \n",
      " |      note: While this function is capable of creating endless amounts of arbitrary\n",
      " |          metadata, it is suggested that property names are drawn from central\n",
      " |          repository, or prefixed with \"x-\". A property that does not follow this\n",
      " |          convention may affect the behavior of transducer in future releases.\n",
      " |  \n",
      " |  shuffle(self, another, harmonize=True)\n",
      " |      Shuffle this transducer with transducer *another*.\n",
      " |      \n",
      " |      If transducer A accepts string 'foo' and transducer B string 'bar', the\n",
      " |      transducer that results from shuffling A and B accepts all strings\n",
      " |      [(f|b)(o|a)(o|r)].\n",
      " |      \n",
      " |      pre: Both transducers must be automata, i.e. map strings onto themselves.\n",
      " |  \n",
      " |  substitute(self, s, S=None, **kwargs)\n",
      " |      Substitute symbols or transitions in the transducer.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `s` :\n",
      " |          The symbol or transition to be substituted. Can also be a dictionary of\n",
      " |          substitutions, if S == None.\n",
      " |      * `S` :\n",
      " |          The symbol, transition, a tuple of transitions or a transducer\n",
      " |          (hfst.HfstTransducer) that substitutes *s*.\n",
      " |      * `kwargs` :\n",
      " |          Arguments recognized are 'input' and 'output', their values can be False or\n",
      " |          True, True being the default. These arguments are valid only if *s* and *S*\n",
      " |          are strings, else they are ignored.\n",
      " |      * `input` :\n",
      " |          Whether substitution is performed on input side, defaults to True. Valid\n",
      " |          only if *s* and *S* are strings.\n",
      " |      * `output` :\n",
      " |          Whether substitution is performed on output side, defaults to True. Valid\n",
      " |          only if *s* and \\ S are strings.\n",
      " |      \n",
      " |      For more information, see hfst.HfstIterableTransducer.substitute. The function\n",
      " |      works similarly, with the exception of argument *S*, which must be\n",
      " |      hfst.HfstTransducer instead of hfst.HfstIterableTransducer.\n",
      " |      \n",
      " |      See also: hfst.HfstIterableTransducer.substitute\n",
      " |  \n",
      " |  subtract(self, tr, harmonize=True)\n",
      " |      Subtract transducer *another* from this transducer.\n",
      " |  \n",
      " |  view(self)\n",
      " |      Return a dot Digraph representation of the transducer as a graphviz.Source object.\n",
      " |      \n",
      " |      Inside a Jupyter notebook, the return value will be automatically\n",
      " |      rendered to an svg image and displayed on the console.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      tr = hfst_dev.regex('foo:bar')\n",
      " |      tr.view()\n",
      " |      \n",
      " |      If inside an intended block, 'display' must be called:\n",
      " |      \n",
      " |      if (Foo):\n",
      " |          tr = hfst_dev.regex('foo:bar')\n",
      " |          display(tr.view())\n",
      " |      \n",
      " |      Note: The function requires graphviz package.\n",
      " |  \n",
      " |  write(self, os)\n",
      " |      Write the transducer in binary format to *ostr*.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `ostr` :\n",
      " |          A hfst.HfstOutputStream where the transducer is written.\n",
      " |  \n",
      " |  write_att(self, f, write_weights=True)\n",
      " |      Write the transducer in AT&T format to file *f*, *write_weights* defined whether\n",
      " |      weights are written.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `f` :\n",
      " |          A python file where transducer is written.\n",
      " |      * `write_weights` :\n",
      " |          Whether weights are written.\n",
      " |  \n",
      " |  write_prolog(self, f, write_weights=True)\n",
      " |      Write the transducer in prolog format with name *name* to file *f*,\n",
      " |      *write_weights* defined whether weights are written.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `f` :\n",
      " |          A python file where the transducer is written.\n",
      " |      * `write_weights` :\n",
      " |          Whether weights are written.\n",
      " |  \n",
      " |  write_to_file(self, filename_)\n",
      " |      Write the transducer in binary format to file *filename_*.\n",
      " |  \n",
      " |  write_xfst(self, f, write_weights=True)\n",
      " |      Write the transducer in xfst format to file *f*, *write_weights* defined whether\n",
      " |      weights are written.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      * `f` :\n",
      " |          A python file where transducer is written.\n",
      " |      * `write_weights` :\n",
      " |          Whether weights are written.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __swig_destroy__ = delete_HfstTransducer(...)\n",
      " |  \n",
      " |  is_implementation_type_available(type)\n",
      " |      Whether HFST is linked to the transducer library needed by implementation type\n",
      " |      *type*.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __swig_getmethods__ = {'is_implementation_type_available': <function H...\n",
      " |  \n",
      " |  __swig_setmethods__ = {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvc = hfst.regex('${can} .o. English', definitions=defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c967be-9ea3-46cd-8007-986ba98a8689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
