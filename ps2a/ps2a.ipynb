{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Preparations\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.16'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import grammar, parse\n",
    "from nltk.parse.generate import generate\n",
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# Grammar Rules\n",
      "S[SEM=<?subj(?vp)>] -> DP[SEM=?subj] VP[SEM=?vp]\n",
      "S[SEM=<?vp(?subj)>] -> NP[SEM=?subj] VP[SEM=?vp]\n",
      "S[SEM=<?vp1(?subj) & ?vp2(?subj)>] -> NP[SEM=?subj] VP[SEM=?vp1] 'and' VP[SEM=?vp2]\n",
      "DP[ SEM=<?X(?P)>] -> Det[SEM=?X] N[SEM=?P] \n",
      "VP[SEM=?Q] -> 'is' A[SEM=?Q]\n",
      "VP[SEM=?P] -> 'is' 'a' N[SEM=?P]\n",
      "# This is included for testing.\n",
      "VP[SEM=<\\x.offend(x)>] -> 'offends'\n",
      "# Transitive verb with individual object.\n",
      "VP[ SEM=<?R(?n)>] -> TV[SEM=?R] NP[SEM=?n]\n",
      "# Transitive verb with quantifier object.\n",
      "# The object is given minimal scope.\n",
      "VP[ SEM=<\\m.?X(\\n.(?R(n)(m)))>] -> TV[SEM=?R] DP[SEM=?X]\n",
      "# Lexical Rules\n",
      "A[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] -> 'vocalic'\n",
      "A[SEM=<\\n.exists c.((-vowel(c)) & char(n,c))>] -> 'consonantal'\n",
      "A[SEM=<\\n.exists c.(capital(n) & char(n,c))>] -> 'capitalized'\n",
      "A[SEM=<\\n. (n = 1) >] -> 'initial'\n",
      "Det[SEM=<\\P Q.all n.(P(n) -> Q(n))>] -> 'every'\n",
      "Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] -> 'a'\n",
      "Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] -> 'some'\n",
      "Det[SEM=<\\P Q.all n.(P(n) -> -Q(n))>] -> 'no'\n",
      "N[SEM=<\\n.char(n,leti)>] -> 'i'\n",
      "N[SEM=<\\n.char(n,lete)>] -> 'e'\n",
      "N[SEM=<\\n.char(n,letu)>] -> 'u'\n",
      "N[SEM=<\\n.char(n,letp)>] -> 'p'\n",
      "N[SEM=<\\n.char(n,lett)>] -> 't'\n",
      "N[SEM=<\\n.char(n,letk)>] -> 'k'\n",
      "N[SEM=<\\n.exists c.(glide(c) & char(n,c))>] -> 'glide'\n",
      "N[SEM=<\\n.exists c.char(n,c)>] -> 'letter'\n",
      "N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] -> 'vowel'\n",
      "N[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>] -> 'consonant'\n",
      "NP[SEM=<1>] -> 'letter' 'one'\n",
      "NP[SEM=<2>] -> 'letter' 'two'\n",
      "NP[SEM=<3>] -> 'letter' 'three'\n",
      "NP[SEM=<4>] -> 'letter' 'four'\n",
      "NP[SEM=<5>] -> 'letter' 'five'\n",
      "TV[SEM=<\\m n.le(m,n)>] -> 'follows'\n",
      "TV[SEM=<\\m n.le(n,m)>] -> 'precedes'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('h2.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists c.(vowel(c) & char(2,c))>]\n",
      "  (NP[SEM=<2>] letter two)\n",
      "  (VP[SEM=<\\n.exists c.(vowel(c) & char(n,c))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vocalic)))\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.load_parser('h2.fcfg', trace=0)\n",
    "sent = 'letter two is vocalic'.split()\n",
    "for tree in cp.parse(sent): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.png](1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use Angela Liu's implementation from mapping the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "----------------\n",
      "Domain = {'3', 'a', 't', '2', 'c', '1'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " 'capital': set(),\n",
      " 'char': {('2', 'a'), ('3', 't'), ('1', 'c')},\n",
      " 'cons': {('t',), ('c',)},\n",
      " 'glide': set(),\n",
      " 'le': {('1', '2'), ('2', '3'), ('1', '3')},\n",
      " 'vowel': {('a',)}}\n",
      "\n",
      "mAtch\n",
      "----------------\n",
      "Domain = {'h', '3', 'a', '5', 'm', 't', '2', '4', 'c', '1'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " '4': '4',\n",
      " '5': '5',\n",
      " 'capital': {('2',)},\n",
      " 'char': {('4', 'c'), ('5', 'h'), ('3', 't'), ('1', 'm'), ('2', 'a')},\n",
      " 'cons': {('m',), ('h',), ('t',), ('c',)},\n",
      " 'glide': set(),\n",
      " 'le': {('1', '2'),\n",
      "        ('1', '3'),\n",
      "        ('1', '4'),\n",
      "        ('1', '5'),\n",
      "        ('2', '3'),\n",
      "        ('2', '4'),\n",
      "        ('2', '5'),\n",
      "        ('3', '4'),\n",
      "        ('3', '5'),\n",
      "        ('4', '5')},\n",
      " 'vowel': {('a',)}}\n",
      "\n",
      "peRiLOuSy\n",
      "----------------\n",
      "Domain = {'6', 'u', '3', '8', '5', 'r', 'o', 'y', 's', '2', '4', '9', '7', '1', 'e', 'l', 'i', 'p'},\n",
      "Valuation = \n",
      "{'1': '1',\n",
      " '2': '2',\n",
      " '3': '3',\n",
      " '4': '4',\n",
      " '5': '5',\n",
      " '6': '6',\n",
      " '7': '7',\n",
      " '8': '8',\n",
      " '9': '9',\n",
      " 'capital': {('8',), ('6',), ('5',), ('3',)},\n",
      " 'char': {('1', 'p'),\n",
      "          ('2', 'e'),\n",
      "          ('3', 'r'),\n",
      "          ('4', 'i'),\n",
      "          ('5', 'l'),\n",
      "          ('6', 'o'),\n",
      "          ('7', 'u'),\n",
      "          ('8', 's'),\n",
      "          ('9', 'y')},\n",
      " 'cons': {('r',), ('p',), ('l',), ('y',), ('s',)},\n",
      " 'glide': {('y',)},\n",
      " 'le': {('1', '2'),\n",
      "        ('1', '3'),\n",
      "        ('1', '4'),\n",
      "        ('1', '5'),\n",
      "        ('1', '6'),\n",
      "        ('1', '7'),\n",
      "        ('1', '8'),\n",
      "        ('1', '9'),\n",
      "        ('2', '3'),\n",
      "        ('2', '4'),\n",
      "        ('2', '5'),\n",
      "        ('2', '6'),\n",
      "        ('2', '7'),\n",
      "        ('2', '8'),\n",
      "        ('2', '9'),\n",
      "        ('3', '4'),\n",
      "        ('3', '5'),\n",
      "        ('3', '6'),\n",
      "        ('3', '7'),\n",
      "        ('3', '8'),\n",
      "        ('3', '9'),\n",
      "        ('4', '5'),\n",
      "        ('4', '6'),\n",
      "        ('4', '7'),\n",
      "        ('4', '8'),\n",
      "        ('4', '9'),\n",
      "        ('5', '6'),\n",
      "        ('5', '7'),\n",
      "        ('5', '8'),\n",
      "        ('5', '9'),\n",
      "        ('6', '7'),\n",
      "        ('6', '8'),\n",
      "        ('6', '9'),\n",
      "        ('7', '8'),\n",
      "        ('7', '9'),\n",
      "        ('8', '9')},\n",
      " 'vowel': {('u',), ('o',), ('i',), ('e',)}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List, Set\n",
    "\n",
    "def to_model_str(word: str, special_rels: List[Callable[[str], str]]=[]) -> str:\n",
    "    \"\"\"\n",
    "    Creates the string form of the model for the input word. This string is meant to be passed to `nltk.Valuation.fromstring`.\n",
    "    By default, the function will only add the relations mapping i => i for i from 1 to the length of `word` and a relation \n",
    "    mapping char => the set of tuples (i, word[i]). The `special_rels` function allows you to specify additional relations to \n",
    "    be added to the valuation string.\n",
    "    \n",
    "    :param word: The word to create a model string for.\n",
    "    :param special_rels: A list of functions that when called return a string of the form {relation_name} => {relation_contents}. Defaults to the empty list.\n",
    "    :returns: a string representing the model for word\n",
    "    \"\"\"\n",
    "    n = len(word)\n",
    "    model_str = []\n",
    "    char = []\n",
    "    for i in range(1, n+1):\n",
    "        model_str.append(f'{i} => {i}')\n",
    "        char.append((i, word[i-1]))\n",
    "    model_str.append(f'char => {set(char)}'.lower())\n",
    "    return '\\n'.join(model_str + [rel(word) for rel in special_rels]).replace(\"'\", \"\")\n",
    "# Angela Liu\n",
    "import re\n",
    "\n",
    "\n",
    "get_vowel = lambda w: f'vowel => {set(re.findall(r\"[AEIOUaeiou]\", w))}'.lower()\n",
    "get_cons = lambda w: 'cons => {}'.format(set(re.findall(r\"[^AEIOUaeiou\\W0-9]\", w))).lower()\n",
    "follows = lambda w: f'le => {set([(i+1,j+1) for i in range(len(w)) for j in range(i, len(w)) if i != j])}'\n",
    "get_capital = lambda w: f'capital => {set([m.span()[0] + 1 for m in re.finditer(r\"[A-Z]\", w)])}'\n",
    "# Angela Liu\n",
    "\n",
    "get_glide = lambda w: f'glide => {set(re.findall(r\"[YWyw]\", w))}'.lower()\n",
    "# added\n",
    "\n",
    "def emptysets(val:nltk.sem.evaluate.Valuation):\n",
    "  val.update([(k,set()) for (k,v) in val.items() if v == 'set()'])\n",
    "\n",
    "words = ['cat', 'mAtch', 'peRiLOuSy']\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_cons, follows, get_capital,get_glide])) for w in words]\n",
    "for v in vals: emptysets(v)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]\n",
    "for w, m in zip(words, models):\n",
    "    print(f'{w}\\n----------------\\n{m}\\n')\n",
    "# Angela Liu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of the work:\n",
    "==="
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Semantics of sentences about strings\n",
    "Computational Linguistics Spring 2023\n",
    "Problems Set 2\n",
    "```\n",
    "\n",
    "The text for this module is the NLTK book\n",
    "Chapter 9. Building Feature Based Grammars and\n",
    "Chapter 10. Analyzing the Meaning of Sentences\n",
    "\n",
    "See also lecture8_2023.ipynb and string_2023.ipynb\n",
    "\n",
    "The purpose of the assingnment is to develop feature-based grammars that include\n",
    "logical semantics, and to evaluate the adequacy of the semantics by computing\n",
    "truth in logically constructed models.  For instance, we want to be able to\n",
    "evaluate whether the sentence\n",
    "\n",
    "   every consonant is capitalized\n",
    "\n",
    "is true or false as description of the word\n",
    "\n",
    "   CINEMA\n",
    "\n",
    "or\n",
    "\n",
    "   Cinema\n",
    "\n",
    "or\n",
    "\n",
    "   CINEmA.\n",
    "\n",
    "In each problem n do these steps. The problem statement gives sentence sn. See\n",
    "Chapters 9 and 10 for the methodology.\n",
    "\n",
    "(i) Define a feature based grammar gn that includes all the words in sentence sn\n",
    "its lexicon.  The feature grammars will usually add a word and/or construction\n",
    "to a base grammar which will be similar to simple-sem.fcfg.  This base grammar\n",
    "will be distributed. (It will be helpful to figure out how to add a lexical item\n",
    "or production to a grammar in Python. Discuss the method for this on the forum.\n",
    "Or you can define the grammar from scratch.)\n",
    "\n",
    "(ii) Parse the sentenced and display the tree.\n",
    "\n",
    "(iii) Map sn to a logical formula fn by parsing with gn and extracting the\n",
    "semantics that annotates the root.\n",
    "\n",
    "(iv) Define a combination four words (serving as models) and the intuitive\n",
    "truth values of sentence sn as a description of the word.\n",
    "\n",
    "(v) Transform the four words into four models or valuations in the sense of\n",
    "Chapter 10. This can be done as in Lecture 8, or by using a function.\n",
    "Code for this may be shared and discussed on the forum.\n",
    "\n",
    "(vi) Evaluate formula fn in the four models to obtain four truth values. Compare them\n",
    "to the target truth values.\n",
    "\n",
    "Work individually, except that code for mapping a word to a valuation may be\n",
    "shared.  Post techinical questions and requests for hints on the forum.\n",
    "\n",
    "Notes\n",
    "The problems are selected so that quantifiers are used only in subject position.\n",
    "So it is not necessary (except perhaps in challenge problems) to apply the strategy\n",
    "from simple-sem.fcfg to fit quantified NPs into object positions.\n",
    "\n",
    "The words 'precedes' and 'follows' are interpreted in the sense of 'not necessarily\n",
    "immediately'.\n",
    "\n",
    "\n",
    "Problems\n",
    "=======\n",
    "\n",
    "1. letter two is consonantal   \n",
    "Base your analysis on 'letter two is vocalic', which is covered by the base grammar.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a grammar rule \n",
    "```\n",
    "A[SEM=<\\n.exists c.(consonant(c) & char(n,c))>] -> 'consonantal'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists c.(-vowel(c) & char(2,c))>]\n",
      "  (NP[SEM=<2>] letter two)\n",
      "  (VP[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>] consonantal)))\n"
     ]
    }
   ],
   "source": [
    "g1 = nltk.load_parser('h2.fcfg', trace=0)\n",
    "s1 = 'letter two is consonantal'\n",
    "s1_split = s1.split()\n",
    "for tree in g1.parse(s1_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the logical formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists c.(-vowel(c) & char(2,c))\n"
     ]
    }
   ],
   "source": [
    "t1=next(g1.parse(s1_split))\n",
    "f1 = t1.label()['SEM']\n",
    "print(f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a sample four word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = [('emu',True),('bat',False),('cat',False),('aka',True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [e[0] for e in e1]\n",
    "truths = [e[1] for e in e1]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter two is consonantal\n",
      "---------------\n",
      "emu\n",
      "True\n",
      "----------------\n",
      "bat\n",
      "False\n",
      "----------------\n",
      "cat\n",
      "False\n",
      "----------------\n",
      "aka\n",
      "True\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s1}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f1),a)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct! emu & aka has the second letter being consonants\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. every vowel precedes letter three\n",
    "   Add a production for 'precedes' to the grammar. Don't add it to the\n",
    "   valuations. Instead, define the semantics of 'precedes' in terms of\n",
    "   the primitive used for 'follows'.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add grammar\n",
    "```\n",
    "TV[SEM=<\\m n.le(n,m)>] -> 'precedes'\n",
    "N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] -> 'vowel'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all n.(exists c.(vowel(c) & char(n,c)) -> le(n,3))>]\n",
      "  (DP[SEM=<\\Q.all n.(exists c.(vowel(c) & char(n,c)) -> Q(n))>]\n",
      "    (Det[SEM=<\\P Q.all n.(P(n) -> Q(n))>] every)\n",
      "    (N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vowel))\n",
      "  (VP[SEM=<\\n.le(n,3)>]\n",
      "    (TV[SEM=<\\m n.le(n,m)>] precedes)\n",
      "    (NP[SEM=<3>] letter three)))\n"
     ]
    }
   ],
   "source": [
    "g2 = nltk.load_parser('h2.fcfg', trace=0,cache=False)\n",
    "s2 = 'every vowel precedes letter three'\n",
    "s2_split = s2.split()\n",
    "for tree in g2.parse(s2_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](g2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all n.(exists c.(vowel(c) & char(n,c)) -> le(n,3))\n"
     ]
    }
   ],
   "source": [
    "t2=next(g2.parse(s2_split))\n",
    "f2 = t2.label()['SEM']\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = [('emmmu',False),('aekjd',True),('maqwr',True),('aeiou',False)]\n",
    "words = [e[0] for e in e2]\n",
    "truths = [e[1] for e in e2]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, follows])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "every vowel precedes letter three\n",
      "---------------\n",
      "emmmu\n",
      "False\n",
      "----------------\n",
      "aekjd\n",
      "True\n",
      "----------------\n",
      "maqwr\n",
      "True\n",
      "----------------\n",
      "aeiou\n",
      "False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s2}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f2),a)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct! emmmu & aeiou is not correct\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. some vowel is capitalized  \n",
    "   You need to add \"capitalized\" to the grammar, and to the valuations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add grammar\n",
    "```\n",
    "A[SEM=<\\n.exists c.(capital(n) & char(n,c))>] -> 'capitalized'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<exists n.(exists c.(vowel(c) & char(n,c)) & exists c.(capital(n) & char(n,c)))>]\n",
      "  (DP[SEM=<\\Q.exists n.(exists c.(vowel(c) & char(n,c)) & Q(n))>]\n",
      "    (Det[SEM=<\\P Q.exists n.(P(n) & Q(n))>] some)\n",
      "    (N[SEM=<\\n.exists c.(vowel(c) & char(n,c))>] vowel))\n",
      "  (VP[SEM=<\\n.exists c.(capital(n) & char(n,c))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(capital(n) & char(n,c))>] capitalized)))\n"
     ]
    }
   ],
   "source": [
    "g3 = nltk.load_parser('h2.fcfg', trace=0,cache=False)\n",
    "s3 = 'some vowel is capitalized'\n",
    "s3_split = s3.split()\n",
    "for tree in g3.parse(s3_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3](g3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists n.(exists c.(vowel(c) & char(n,c)) & exists c.(capital(n) & char(n,c)))\n"
     ]
    }
   ],
   "source": [
    "t3=next(g3.parse(s3_split))\n",
    "f3 = t3.label()['SEM']\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = [('emmmu',False),('aEkjd',True),('mAEOwr',True),('aeiou',False)]\n",
    "words = [e[0] for e in e3]\n",
    "truths = [e[1] for e in e3]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_capital])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some vowel is capitalized\n",
      "---------------\n",
      "emmmu\n",
      "False\n",
      "----------------\n",
      "aEkjd\n",
      "True\n",
      "----------------\n",
      "mAEOwr\n",
      "True\n",
      "----------------\n",
      "aeiou\n",
      "False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s3}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f3),a,trace=None)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```diff\n",
    "+ The answer is correct! aEkjd & mAEOwr has capitalized vowel(s)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. no glide is capitalized  \n",
    "  The glides are \"y\" and \"w\". Define \"no\", with the same semantic\n",
    "    type as \"every\" and \"some\". Include a constant 'glide' in the valuations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add grammar\n",
    "```\n",
    "Det[SEM=<\\P Q.all n.(P(n) -> -Q(n))>] -> 'no'\n",
    "N[SEM=<\\n.exists c.(glide(c) & char(n,c))>] -> 'glide'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in function\n",
    "```\n",
    "get_glide = lambda w: f'glide => {set(re.findall(r\"[YWyw]\", w))}'.lower()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all n.(exists c.(glide(c) & char(n,c)) -> -exists c.(capital(n) & char(n,c)))>]\n",
      "  (DP[SEM=<\\Q.all n.(exists c.(glide(c) & char(n,c)) -> -Q(n))>]\n",
      "    (Det[SEM=<\\P Q.all n.(P(n) -> -Q(n))>] no)\n",
      "    (N[SEM=<\\n.exists c.(glide(c) & char(n,c))>] glide))\n",
      "  (VP[SEM=<\\n.exists c.(capital(n) & char(n,c))>]\n",
      "    is\n",
      "    (A[SEM=<\\n.exists c.(capital(n) & char(n,c))>] capitalized)))\n"
     ]
    }
   ],
   "source": [
    "g4 = nltk.load_parser('h2.fcfg', trace=0,cache=False)\n",
    "s4 = 'no glide is capitalized'\n",
    "s4_split = s4.split()\n",
    "for tree in g4.parse(s4_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![4](g4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all n.(exists c.(glide(c) & char(n,c)) -> -exists c.(capital(n) & char(n,c)))\n"
     ]
    }
   ],
   "source": [
    "t4=next(g4.parse(s4_split))\n",
    "f4 = t4.label()['SEM']\n",
    "print(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4 = [('emwywu',True),('aEWWWjd',False),('mAEOwr',True),('aeYWou',False)]\n",
    "words = [e[0] for e in e4]\n",
    "truths = [e[1] for e in e4]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel, get_capital,get_glide])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no glide is capitalized\n",
      "---------------\n",
      "emwywu\n",
      "True\n",
      "----------------\n",
      "aEWWWjd\n",
      "False\n",
      "----------------\n",
      "mAEOwr\n",
      "True\n",
      "----------------\n",
      "aeYWou\n",
      "False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s4}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f4),a,trace=None)}\\n----------------')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` diff\n",
    "+ Correct!\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. letter one is initial and is a consonant  \n",
    "   Define \"initial\", meaning 'is at the start of the word' in terms\n",
    "   of the available primitives.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add grammar\n",
    "```\n",
    "\n",
    "S[SEM=<?vp1(?subj) & ?vp2(?subj)>] -> NP[SEM=?subj] VP[SEM=?vp1] 'and' VP[SEM=?vp2]\n",
    "VP[SEM=?P] -> 'is' 'a' N[SEM=?P]\n",
    "A[SEM=<\\n. (n = 1) >] -> 'initial'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<((1 = 1) & exists c.(-vowel(c) & char(1,c)))>]\n",
      "  (NP[SEM=<1>] letter one)\n",
      "  (VP[SEM=<\\n.(n = 1)>] is (A[SEM=<\\n.(n = 1)>] initial))\n",
      "  and\n",
      "  (VP[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>]\n",
      "    is\n",
      "    a\n",
      "    (N[SEM=<\\n.exists c.(-vowel(c) & char(n,c))>] consonant)))\n"
     ]
    }
   ],
   "source": [
    "g5 = nltk.load_parser('h2.fcfg', trace=0,cache=False)\n",
    "s5 = 'letter one is initial and is a consonant  '\n",
    "s5_split = s5.split()\n",
    "for tree in g5.parse(s5_split): print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5](g5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1 = 1) & exists c.(-vowel(c) & char(1,c)))\n"
     ]
    }
   ],
   "source": [
    "t5=next(g5.parse(s5_split))\n",
    "f5 = t5.label()['SEM']\n",
    "print(f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5 = [('emwywu',True),('aEWWWjd',False),('mAEOwr',True),('aeYWou',False)]\n",
    "words = [e[0] for e in e5]\n",
    "truths = [e[1] for e in e5]\n",
    "vals = [nltk.Valuation.fromstring(to_model_str(w, [get_vowel])) for w in words]\n",
    "assignments = [nltk.Assignment(val.domain) for val in vals]\n",
    "for val in vals: emptysets(val)\n",
    "models = [nltk.Model(val.domain, val) for val in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter one is initial and is a consonant  \n",
      "---------------\n",
      "emwywu\n",
      "False\n",
      "----------------\n",
      "aEWWWjd\n",
      "False\n",
      "----------------\n",
      "mAEOwr\n",
      "True\n",
      "----------------\n",
      "aeYWou\n",
      "False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(f'{s5}\\n---------------')\n",
    "for w, a, m in zip(words, assignments, models):\n",
    "    print(f'{w}\\n{m.evaluate(str(f5),a,trace=0)}\\n----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` diff\n",
    "+ Correct!\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompLing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efd08fb7d61c09f4aaea9e8ceb0bf572fefe064d17a4cedc1b735c081f854a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
